{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "mps:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel, PhrasalConstraint, QuantoConfig\n",
    "\n",
    "from analysis.toolbox import *\n",
    "from undecorated import undecorated\n",
    "from types import MethodType\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "torch.set_default_device(device)\n",
    "print(f\"Using {device} device\")\n",
    "print(torch.tensor([1, 2, 3]).device)\n",
    "\n",
    "\n",
    "# MAGICKS --------------------------\n",
    "s_model = \"gpt2\"\n",
    "iSeed = 4523522\n",
    "\n",
    "iEncodingDim = 2\n",
    "iOutputSize = 768\n",
    "iMaxTokens = 15\n",
    "\n",
    "torch.manual_seed(iSeed)\n",
    "model = GPT2LMHeadModel.from_pretrained(s_model, device_map=device, resume_download=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(s_model, resume_download=True)\n",
    "\n",
    "# TODO: Link to this https://github.com/huggingface/transformers/issues/15552 (last comment)\n",
    "generate_with_grad = model.generate.__closure__[1].cell_contents\n",
    "#generate_with_grad = undecorated(model.generate)\n",
    "model.generate_with_grad = MethodType(generate_with_grad, model)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sPathGenerator = \"../mlartifacts/337721250762804550/4c5cb926a7854be1bf6af4c2f6b505f7/artifacts/models/data/model.pth\"\n",
    "sPathPredictor = \"classifier.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Generator\n",
    "$p(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = torch.load(sPathGenerator)\n",
    "generator = ae.decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Classifier\n",
    "$p(y|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Implement this more robustly; This must match the arch. in the classifier\n",
    "# NOTE: Think about whether the generator training claims can be part of the class. training data\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, output_size)\n",
    "        self.fc2 = nn.Linear(input_size, 192)\n",
    "        self.fc3 = nn.Linear(192, 48)\n",
    "        self.fc3 = nn.Linear(192, 48)\n",
    "        self.fc4 = nn.Linear(48, output_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# load model\n",
    "classifier = torch.load(sPathPredictor)\n",
    "#classifier.eval()\n",
    "\n",
    "def fnPreProcessor(x):\n",
    "    print(x.shape)\n",
    "    # return shape: iClaims x iTokens x iEmbeddingSize\n",
    "    tokens = model.generate_with_grad(inputs_embeds = x.unsqueeze(1),\n",
    "               max_new_tokens = iMaxTokens,\n",
    "               pad_token_id = tokenizer.pad_token_id)\n",
    "    \n",
    "    print(tokens)\n",
    "    \n",
    "    # apply the input embedding and mean pool across tokens\n",
    "    tReturn = model.get_input_embeddings()(tokens).mean(dim=1)\n",
    "    return tReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7500, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# BUG: Are these part of the classifier training data? For validation, they shouldn't be\n",
    "lTargetStrings = [\n",
    "    \"Experience 50% more visible shine after just one use.\", #0\n",
    "    \"Formulated with light-reflecting technology for a glossy finish.\", #1\n",
    "    \"Transform dull strands into radiant, luminous locks.\", #2\n",
    "    \"Infused with nourishing oils that enhance natural shine.\", #3\n",
    "    \"See instant brilliance with our advanced shine-boosting formula.\", #4\n",
    "    \"Locks in moisture to amplify hair's natural luster.\", #5\n",
    "    \"Achieve salon-quality shine without leaving home.\", #6\n",
    "    \"Visible reduction in dullness, replaced with stunning shine.\", #7\n",
    "    \"Say goodbye to lackluster hair, hello to mirror-like shine.\", #8\n",
    "    \"Clinically proven to enhance shine by up to 70%.\", # ^tangible #9\n",
    "    \"Elevate your confidence with hair that gleams under any light.\", #10\n",
    "    \"Embrace the allure of luminous hair that turns heads.\", #11\n",
    "    \"Unleash the power of radiant hair that speaks volumes.\", #12\n",
    "    \"Transform your look with hair that exudes brilliance.\", #13\n",
    "    \"Feel the difference of hair that shines with vitality and health.\", #14\n",
    "    \"Rediscover the joy of hair that beams with inner vibrancy.\", #15\n",
    "    \"Indulge in the luxury of hair that shimmers with elegance.\", #16\n",
    "    \"Step into the spotlight with hair that radiates beauty.\", #17\n",
    "    \"Experience the magic of hair that dazzles with every movement.\", #18\n",
    "    \"Unlock the secret to hair that shines from within, reflecting your inner glow.\" #19,\n",
    "]\n",
    "\n",
    "tTargetStrings, lLengths = TokenizeClaims(lTargetStrings, tokenizer)\n",
    "tInputEmbeddings = model.get_input_embeddings()(tTargetStrings).mean(dim=1)\n",
    "\n",
    "_, prediction = torch.max(classifier(tInputEmbeddings), 1)\n",
    "\n",
    "print(((prediction[:10] == 1).sum() + (prediction[10:] == 0).sum()) / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morpher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoener/miniforge3/envs/mphil/lib/python3.9/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tGenerationPoint = torch.tensor(torch.randn(1, 2), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience 50\n",
      "\n",
      "% ( image only sees best for less<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "tGenerationPoint, tGenerationPoint.shape\n",
    "\n",
    "print(tokenizer.decode(model.generate(inputs_embeds = generator(tGenerationPoint).unsqueeze(1),\n",
    "               max_new_tokens = iMaxTokens,\n",
    "               pad_token_id = tokenizer.pad_token_id)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tOutputGenerator = generator(tGenerationPoint)\n",
    "tOutputGenerator.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoener/miniforge3/envs/mphil/lib/python3.9/site-packages/torch/utils/_device.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n",
      "tensor([[ 8479,  4817,    12,   259,    12, 43701,    13, 50256]],\n",
      "       device='mps:0')\n",
      "torch.Size([1, 768])\n",
      "tensor([2.8088e-09], device='mps:0', grad_fn=<SelectBackward0>)\n",
      "tensor([1.], device='mps:0', grad_fn=<AbsBackward0>)\n",
      "torch.Size([1, 1, 768])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[327], line 40\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(tOutputGenerator\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# tOld = tGenerationPoint.clone()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# # make prediction based on the sequence from this point\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#         logits = model(inputs_embeds = tNextEmbedding).logits\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#         tNextEmbedding = torch.cat((tOldEmbedding, model.get_input_embeddings()(torch.argmax(logits)).unsqueeze(0)), dim=0)\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_with_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtOutputGenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43miMaxTokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m           \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# tInputClassifier = tNextEmbedding.clone()\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# # apply the input embedding and mean pool across tokens\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#tInputClassifier = model.get_input_embeddings()(tokens).mean(dim=1)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# iInputClassifier = fnPreProcessor(tOutputGenerator)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/mphil/lib/python3.9/site-packages/transformers/generation/utils.py:1610\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assisted_decoding(\n\u001b[1;32m   1594\u001b[0m         input_ids,\n\u001b[1;32m   1595\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1607\u001b[0m     )\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1610\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_greedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1624\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "dLearningRate = 1e-5\n",
    "tGenerationPoint = torch.tensor(torch.randn(1, 2))\n",
    "tTestPoint = model.get_input_embeddings()(tokenizer.encode(\"Feel the confidence and allure\", return_tensors=\"pt\")).mean(dim=1).detach()\n",
    "#tGenerationPoint = torch.tensor(tInitPoint, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([tTestPoint], lr=dLearningRate, maximize=False)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "plt.plot(tGenerationPoint.detach().cpu().numpy()[0, 0],\n",
    "         tGenerationPoint.detach().cpu().numpy()[0, 1], '.')\n",
    "\n",
    "iClassIdx = 1\n",
    "iEpoch = 0\n",
    "iEpochMax = 100 # failswitch\n",
    "dCriterion = 1e-1 # when class 1 probability above dCriterion, stop\n",
    "iTargetValue = torch.tensor([1])\n",
    "\n",
    "# start optimization\n",
    "while True:\n",
    "    \n",
    "    iEpoch += 1\n",
    "    \n",
    "    # generate from point\n",
    "    tOutputGenerator = generator(tGenerationPoint).unsqueeze(1)\n",
    "    print(tOutputGenerator.shape)\n",
    "    # tOld = tGenerationPoint.clone()\n",
    "\n",
    "    # # make prediction based on the sequence from this point\n",
    "    # # BUG: Can I switch this for generate_with_grad?\n",
    "    # # BUG: Argmax could be the problem ...\n",
    "    # for i in range(1, iMaxTokens + 1):\n",
    "    #     if i == 1:\n",
    "    #         logits = model(inputs_embeds = tOutputGenerator).logits\n",
    "    #         tNextEmbedding = torch.stack((tOutputGenerator.squeeze(), model.get_input_embeddings()(torch.argmax(logits))), dim=0)\n",
    "    #     else:\n",
    "    #         tOldEmbedding = tNextEmbedding.clone()\n",
    "    #         logits = model(inputs_embeds = tNextEmbedding).logits\n",
    "    #         tNextEmbedding = torch.cat((tOldEmbedding, model.get_input_embeddings()(torch.argmax(logits)).unsqueeze(0)), dim=0)\n",
    "    \n",
    "    out = model.generate_with_grad(inputs_embeds = tOutputGenerator,\n",
    "               max_new_tokens = iMaxTokens,\n",
    "               pad_token_id = tokenizer.pad_token_id)\n",
    "    print(out)\n",
    "    # tInputClassifier = tNextEmbedding.clone()\n",
    "    # # apply the input embedding and mean pool across tokens\n",
    "    #tInputClassifier = model.get_input_embeddings()(tokens).mean(dim=1)\n",
    "    # iInputClassifier = fnPreProcessor(tOutputGenerator)\n",
    "    print(iInputClassifier.shape)\n",
    "    tOutputClassifier = classifier(tTestPoint)\n",
    "    # perform optimizer step from here\n",
    "    optimizer.zero_grad()\n",
    "    print(tOutputClassifier[:, iClassIdx])\n",
    "    distance = torch.abs(1 - tOutputClassifier[:, iClassIdx])\n",
    "    print(distance)\n",
    "    #distance = torch.norm(torch.ones([1, 2]) - tOutputClassifier)\n",
    "\n",
    "    distance.backward(retain_graph=True)\n",
    "    #print(\"value\", tOutputClassifier[:, iClassIdx])\n",
    "    #print(\"distance\", distance.item())\n",
    "    #print(\"point\", tGenerationPoint.detach().cpu().numpy())\n",
    "    optimizer.step()\n",
    "\n",
    "    plt.plot(tGenerationPoint.detach().cpu().numpy()[0, 0], tGenerationPoint.detach().cpu().numpy()[0, 1], '.')\n",
    "    #plt.show()\n",
    "    \n",
    "    if distance < dCriterion:\n",
    "        break\n",
    "    \n",
    "    if iEpoch >= iEpochMax:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aNewClaim = tOutputGenerator.detach().cpu().numpy()\n",
    "plt.plot(aNewClaim[0, 0], aNewClaim[0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "dLearningRate = 1e-1\n",
    "tGenerationPoint = torch.tensor(torch.randn(1, 2), requires_grad=True)\n",
    "optimizer = torch.optim.Adam([tGenerationPoint], lr=dLearningRate, maximize=False)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "plt.plot(tGenerationPoint.detach().cpu().numpy()[0, 0],\n",
    "         tGenerationPoint.detach().cpu().numpy()[0, 1])\n",
    "plt.show()\n",
    "\n",
    "iClassIdx = 1\n",
    "iEpoch = 0\n",
    "iEpochMax = 1000 # failswitch\n",
    "dCriterion = 9e-1 # allowed distance loss between target and generated\n",
    "dTargetValue = 2\n",
    "\n",
    "# start optimization\n",
    "while True:\n",
    "    \n",
    "    iEpoch += 1\n",
    "    \n",
    "    # generate from point\n",
    "    tOutputGenerator = generator(tGenerationPoint)\n",
    "    \n",
    "    # make prediction based on the sequence from this point\n",
    "    tOutputRegressor = regressor(fnPreProcessor(tOutputGenerator))\n",
    "    \n",
    "    # perform optimizer step from here\n",
    "    optimizer.zero_grad()\n",
    "    distance = criterion(tOutputRegressor, dTargetValue)\n",
    "    distance.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(distance)\n",
    "    plt.plot(tGenerationPoint.detach().cpu().numpy()[0, 0], tGenerationPoint.detach().cpu().numpy()[0, 1])\n",
    "    plt.show()\n",
    "    \n",
    "    if distance > dCriterion:\n",
    "        break\n",
    "    \n",
    "    if iEpoch >= iEpochMax:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
