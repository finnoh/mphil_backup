@article{ariholtzmanCuriousCaseNeural2020,
  title = {The {{Curious Case}} of {{Neural Text Degeneration}}},
  author = {{Ari Holtzman} and Holtzman, Ari and {Jan Buys} and Buys, Jan and {Leo Du} and Du, Leo and {Maxwell Forbes} and Forbes, Maxwell and {Yejin Choi} and Choi, Yejin},
  year = {2020},
  month = apr,
  abstract = {Despite considerable advances in neural language modeling, it remains an open question what the best decoding strategy is for text generation from a language model (e.g. to generate a story). The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, maximization-based decoding methods such as beam search lead to degeneration --- output text that is bland, incoherent, or gets stuck in repetitive loops. To address this we propose Nucleus Sampling, a simple but effective method to draw considerably higher quality text out of neural language models. Our approach avoids text degeneration by truncating the unreliable tail of the probability distribution, sampling from the dynamic nucleus of tokens containing the vast majority of the probability mass. To properly examine current maximization-based and stochastic decoding methods, we compare generations from each of these methods to the distribution of human text along several axes such as likelihood, diversity, and repetition. Our results show that (1) maximization is an inappropriate decoding objective for open-ended text generation, (2) the probability distributions of the best current language models have an unreliable tail which needs to be truncated during generation and (3) Nucleus Sampling is the best decoding strategy for generating long-form text that is both high-quality --- as measured by human evaluation --- and as diverse as human-written text.},
  keywords = {generation,Generative AI,llm},
  annotation = {MAG ID: 2996287690}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? ðŸ¦œ},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  month = mar,
  pages = {610--623},
  publisher = {ACM},
  address = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  urldate = {2023-06-26},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/I8MP3WNP/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf}
}

@misc{brandUsingGPTMarket2023a,
  type = {{{SSRN Scholarly Paper}}},
  title = {Using {{GPT}} for {{Market Research}}},
  author = {Brand, James and Israeli, Ayelet and Ngwe, Donald},
  year = {2023},
  month = mar,
  number = {4395751},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4395751},
  urldate = {2024-06-04},
  abstract = {Large language models (LLMs) have quickly become popular as labor-augmenting tools for programming, writing, and many other processes that benefit from quick text generation. In this paper we explore the uses and benefits of LLMs for researchers and practitioners who aim to understand consumer preferences. We focus on the distributional nature of LLM responses, and query the Generative Pre-trained Transformer 3.5 (GPT-3.5) model to generate hundreds of survey responses to each prompt. We offer two sets of results to illustrate our approach and assess it. First, we show that GPT-3.5, a widely-used LLM, responds to sets of survey questions in ways that are consistent with economic theory and well-documented patterns of consumer behavior, including downward-sloping demand curves and state dependence. Second, we show that estimates of willingness-to-pay for products and features generated by GPT-3.5 are of realistic magnitudes and match estimates from a recent study that elicited preferences from human consumers. We also offer preliminary guidelines for how best to query information from GPT-3.5 for marketing purposes and discuss potential limitations.},
  langid = {english},
  keywords = {AI,Conjoint,Consumer preferences,Generative Pre-trained Transformer (GPT),Large language models (LLMs),Market research},
  file = {/Users/hoener/Zotero/storage/UCA8AY2P/Brand et al. - 2023 - Using GPT for Market Research.pdf}
}

@article{cathyoneilWeaponsMathDestruction2016,
  title = {Weapons of {{Math Destruction}}: {{How Big Data Increases Inequality}} and {{Threatens Democracy}}},
  author = {{Cathy O'Neil} and O'Neil, Cathy and {Cathy O'Neil}},
  year = {2016},
  month = sep,
  abstract = {A former Wall Street quant sounds an alarm on the mathematical models that pervade modern life and threaten to rip apart our social fabricWe live in the age of the algorithm. Increasingly, the decisions that affect our liveswhere we go to school, whether we get a car loan, how much we pay for health insuranceare being made not by humans, but by mathematical models. In theory, this should lead to greater fairness: Everyone is judged according to the same rules, and bias is eliminated. But as Cathy ONeil reveals in this urgent and necessary book, the opposite is true. The models being used today are opaque, unregulated, and uncontestable, even when theyre wrong. Most troubling, they reinforce discrimination: If a poor student cant get a loan because a lending model deems him too risky (by virtue of his zip code), hes then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues. Models are propping up the lucky and punishing the downtrodden, creating a toxic cocktail for democracy. Welcome to the dark side of Big Data. Tracing the arc of a persons life, ONeil exposes the black box models that shape our future, both as individuals and as a society. These weapons of math destruction score teachers and students, sort rsums, grant (or deny) loans, evaluate workers, target voters, set parole, and monitor our health. ONeil calls on modelers to take more responsibility for their algorithms and on policy makers to regulate their use. But in the end, its up to us to become more savvy about the models that govern our lives. This important book empowers us to ask the tough questions, uncover the truth, and demand change.},
  annotation = {MAG ID: 2573660794}
}

@article{chandraPersonalizationPersonalizedMarketing2022,
  title = {Personalization in Personalized Marketing: {{Trends}} and Ways Forward},
  shorttitle = {Personalization in Personalized Marketing},
  author = {Chandra, Shobhana and Verma, Sanjeev and Lim, Weng Marc and Kumar, Satish and Donthu, Naveen},
  year = {2022},
  journal = {Psychology \& Marketing},
  volume = {39},
  number = {8},
  pages = {1529--1562},
  issn = {1520-6793},
  doi = {10.1002/mar.21670},
  urldate = {2024-06-04},
  abstract = {In marketing, personalization is the action of designing and producing in ways that resonate with customer preferences. Content and products that are personalized according to customer preferences can reduce customer fatigue and time in making choices, thereby decreasing their cognitive load. Despite its importance, the literature on personalized marketing remains fragmented due to the absence of a comprehensive review that consolidates the intellectual structure of the field. This study bridges this knowledge gap through a bibliometric review using performance analysis and science mapping. Through a comprehensive review of 383 publications, this study reveals the publication and citation trends, the most prolific authors, journals, and publications, and six major themes (i.e., personalized recommendation, personalized relationship, personalization--privacy paradox, personalized advertising, personalization concept and discourse in marketing, and customer insights in personalized marketing) that characterize the body of knowledge of personalized marketing. The study concludes with future research directions as ways forward for personalized marketing, wherein a focus on new-age technologies involving artificial intelligence, big data, blockchain, internet of things, and wearables is encouraged to explore new ways to curate personalized experiences across online and offline channels.},
  copyright = {{\copyright} 2022 The Authors. Psychology \& Marketing published by Wiley Periodicals LLC.},
  langid = {english},
  keywords = {advertising,bibliometric,customer insight,paradox,personalization,personalized marketing,privacy,recommendation,relationship,review,trends,ways forward}
}

@article{coyleRiseAICopilots2023,
  title = {The Rise of {{AI}} Copilots: {{How LLMs}} Turn Data into Actions, Advance the Business Intelligence Industry and Make Data Accessible Company-Wide},
  shorttitle = {The Rise of {{AI}} Copilots},
  author = {Coyle, Jeff and Jeske, Stephen},
  year = {2023},
  month = dec,
  journal = {Applied Marketing Analytics},
  volume = {9},
  number = {3},
  pages = {207--214},
  abstract = {AI-powered collaboration is quickly advancing due to a convergence of technologies like large language models and language model programming. These developments have spawned the rise of AI (artificial intelligence) copilots, which are changing the way marketing analysts make decisions and boost productivity. This paper explores the capabilities of AI copilots and delves into the challenges, ethical considerations and data privacy issues that come with their adoption. It discusses real-world applications and future trends in the AI copilot landscape. The paper also emphasises the importance of data integration and personalisation in marketing strategies and offers insights into training and skill development for effective collaboration with AI copilots. This comprehensive analysis aims to equip marketing analytics professionals for the future of AI-powered collaboration.},
  keywords = {AI-powered collaborator,artificial intelligence copilot,knowledge graph,language model query language,large language model}
}

@article{defreitasChatbotsMentalHealth,
  title = {Chatbots and Mental Health: {{Insights}} into the Safety of Generative {{AI}}},
  shorttitle = {Chatbots and Mental Health},
  author = {De Freitas, Julian and U{\u g}uralp, Ahmet Kaan and {O{\u g}uz-U{\u g}uralp}, Zeliha and Puntoni, Stefano},
  journal = {Journal of Consumer Psychology},
  volume = {n/a},
  number = {n/a},
  issn = {1532-7663},
  doi = {10.1002/jcpy.1393},
  urldate = {2024-06-04},
  abstract = {Chatbots are now able to engage in sophisticated conversations with consumers. Due to the ``black box'' nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and ``companion AI'': Applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: Actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a nonnegligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies.},
  copyright = {{\copyright} 2023 Society for Consumer Psychology.},
  langid = {english},
  keywords = {artificial intelligence,chatbots,ethics,generative AI,large language models,mental health},
  file = {/Users/hoener/Zotero/storage/E8DWL3QX/De Freitas et al. - Chatbots and mental health Insights into the safe.pdf}
}

@article{devlinBERTPretrainingDeep2018,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1810.04805},
  urldate = {2023-07-09},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Computation and Language (cs.CL),embedding,FOS: Computer and information sciences,notion}
}

@article{diederikp.kingmaAdamMethodStochastic2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  author = {{Diederik P. Kingma} and Kingma, Diederik P. and {Jimmy Ba} and Ba, Jimmy},
  year = {2014},
  month = dec,
  journal = {arXiv: Learning},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords = {optimization},
  annotation = {MAG ID: 1522301498}
}

@incollection{eggersChoiceBasedConjointAnalysis2022,
  title = {Choice-{{Based Conjoint Analysis}}},
  booktitle = {Handbook of {{Market Research}}},
  author = {Eggers, Felix and Sattler, Henrik and Teichert, Thorsten and V{\"o}lckner, Franziska},
  editor = {Homburg, Christian and Klarmann, Martin and Vomberg, Arnd},
  year = {2022},
  pages = {781--819},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-57413-4_23},
  urldate = {2024-05-28},
  isbn = {978-3-319-57411-0 978-3-319-57413-4},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/72IJB6VU/Eggers et al. - 2022 - Choice-Based Conjoint Analysis.pdf}
}

@article{emilyshengWomanWorkedBabysitter2019,
  title = {The {{Woman Worked}} as a {{Babysitter}}: {{On Biases}} in {{Language Generation}}},
  author = {{Emily Sheng} and Sheng, Emily and {Kai-Wei Chang} and Chang, Kai-Wei and {Kai-Wei Chang} and {Premkumar Natarajan} and Natarajan, Premkumar and {Premkumar Natarajan} and Natarajan, Premkumar and {Nanyun Peng} and Peng, Nanyun},
  year = {2019},
  month = nov,
  pages = {3405--3410},
  doi = {10.18653/v1/d19-1339},
  abstract = {We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.},
  keywords = {biases,ethics,llm},
  annotation = {MAG ID: 2971307358}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  abstract = {"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors"--Publisher's description},
  isbn = {978-0-262-33737-3},
  langid = {english},
  keywords = {notion},
  annotation = {OCLC: 1183962587},
  file = {/Users/hoener/Downloads/goodfellowDeepLearning2016.pdf}
}

@article{haleemArtificialIntelligenceAI2022,
  title = {Artificial Intelligence ({{AI}}) Applications for Marketing: {{A}} Literature-Based Study},
  shorttitle = {Artificial Intelligence ({{AI}}) Applications for Marketing},
  author = {Haleem, Abid and Javaid, Mohd and Asim Qadri, Mohd and Pratap Singh, Ravi and Suman, Rajiv},
  year = {2022},
  month = jan,
  journal = {International Journal of Intelligent Networks},
  volume = {3},
  pages = {119--132},
  issn = {2666-6030},
  doi = {10.1016/j.ijin.2022.08.005},
  urldate = {2024-06-04},
  abstract = {Artificial Intelligence (AI) has vast potential in marketing. It aids in proliferating information and data sources, improving software's data management capabilities, and designing intricate and advanced algorithms. AI is changing the way brands and users interact with one another. The application of this technology is highly dependent on the nature of the website and the type of business. Marketers can now focus more on the customer and meet their needs in real time. By using AI, they can quickly determine what content to target customers and which channel to employ at what moment, thanks to the data collected and generated by its algorithms. Users feel at ease and are more inclined to buy what is offered when AI is used to personalise their experiences. AI tools can also be used to analyse the performance of a competitor's campaigns and reveal their customers' expectations. Machine Learning (ML) is a subset of AI that allows computers to analyse and interpret data without being explicitly programmed. Furthermore, ML assists humans in solving problems efficiently. The algorithm learns and improves performance and accuracy as more data is fed into the algorithm. For this research, relevant articles on AI in marketing are identified from Scopus, Google scholar, researchGate and other platforms. Then these articles were read, and the theme of the paper was developed. This paper attempts to review the role of AI in marketing. The specific applications of AI in various marketing segments and their transformations for marketing sectors are examined. Finally, critical applications of AI for marketing are recognised and analysed.},
  keywords = {Applications,Artificial intelligence (AI),Customer,Data analysis,Decision,Generative AI,Marketing},
  file = {/Users/hoener/Zotero/storage/3P7TFQ7I/S2666603022000136.html}
}

@misc{hartmannPowerGenerativeMarketing2024,
  type = {{{SSRN Scholarly Paper}}},
  title = {The Power of Generative Marketing: {{Can}} Generative {{AI}} Create Superhuman Visual Marketing Content?},
  shorttitle = {The Power of Generative Marketing},
  author = {Hartmann, Jochen and Exner, Yannick and Domdey, Samuel},
  year = {2024},
  month = apr,
  number = {4597899},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4597899},
  urldate = {2024-06-04},
  abstract = {Generative AI's capacity to create photorealistic images has the potential to augment human creativity and disrupt the economics of visual marketing content production. This research systematically compares the performance of AI-generated to human-made marketing images across important marketing dimensions. First, we prompt seven state-of-the-art generative text-to-image models (DALL-E 3, Midjourney v6, Firefly 2, Imagen 2, Imagine, Realistic Vision, and Stable Diffusion XL Turbo) to create 10,320 synthetic marketing images, using 2,400 real-world, human-made images as input. 254,400 human evaluations of these images show that AI-generated marketing imagery can surpass human-made images in quality, realism, and aesthetics. Second, we give identical creative briefings to commissioned human freelancers and the AI models, showing that the best synthetic images also excel in ad creativity, ad attitudes, and prompt following. Third, a randomized field experiment with more than 173,000 impressions demonstrates that AI-generated online ads can compete with professional human-made stock photography, achieving an up to 50\% higher click-through rate than a human-made image. Collectively, our findings suggest that the paradigm shift brought about by generative AI can help advertisers produce marketing content not only faster and orders of magnitude cheaper but also at superhuman effectiveness levels with important implications for firms, consumers, and policymakers. To facilitate future research on AI-generated marketing imagery, we release ``GeneratedImageNet'' that contains all of our synthetic images and their human ratings.},
  langid = {english},
  keywords = {artificial intelligence,content creation,digital marketing,generative AI,marketing effectiveness,productivity}
}

@article{hermannArtificialIntelligenceConsumer2024,
  title = {Artificial Intelligence and Consumer Behavior: {{From}} Predictive to Generative {{AI}}},
  shorttitle = {Artificial Intelligence and Consumer Behavior},
  author = {Hermann, Erik and Puntoni, Stefano},
  year = {2024},
  month = jul,
  journal = {Journal of Business Research},
  volume = {180},
  pages = {114720},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2024.114720},
  urldate = {2024-06-04},
  abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI's remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15~years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.},
  keywords = {Algorithms,Artificial intelligence,Consumer behavior,Generative AI,Predictive AI}
}

@misc{huggingfaceGenerateText,
  title = {How to Generate Text: Using Different Decoding Methods for Language Generation with {{Transformers}} --- Huggingface.Co}
}

@article{ianj.goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {{Ian J. Goodfellow} and Goodfellow, Ian and Salvaris, Mathew and {Jean Pouget-Abadie} and Dean, Danielle and {Pouget-Abadie}, Jean and {Mehdi Mirza} and Tok, Wee Hyong and Mirza, Mehdi and {Bing Xu} and Xu, Bing and {David Warde-Farley} and {Warde-Farley}, David and {Sherjil Ozair} and Ozair, Sherjil and {Aaron Courville} and Courville, Aaron and {Yoshua Bengio} and Bengio, Yoshua},
  year = {2014},
  month = jun,
  journal = {arXiv: Machine Learning},
  doi = {10.1007/978-1-4842-3679-6_8},
  abstract = {For many AI projects, deep learning techniques are increasingly being used as the building blocks for innovative solutions ranging from image classification to object detection, image segmentation, image similarity, and text analytics (e.g., sentiment analysis, key phrase extraction). GANs, first introduced by Goodfellow et al. (2014), are emerging as a powerful new approach toward teaching computers how to do complex tasks through a generative process. As noted by Yann LeCun (at http://bit.ly/LeCunGANs ), GANs are truly the ``coolest idea in machine learning in the last 20 years.''},
  annotation = {MAG ID: 1710476689}
}

@article{jeffreypenningtonGloveGlobalVectors2014,
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  author = {{Jeffrey Pennington} and Pennington, Jeffrey and {Richard Socher} and Socher, Richard and {Christopher Manning} and Manning, Christopher D.},
  year = {2014},
  month = oct,
  pages = {1532--1543},
  doi = {10.3115/v1/d14-1162},
  abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75\% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
  annotation = {MAG ID: 2250539671}
}

@article{liFrontiersDeterminingValidity2024a,
  title = {Frontiers: {{Determining}} the {{Validity}} of {{Large Language Models}} for {{Automated Perceptual Analysis}}},
  shorttitle = {Frontiers},
  author = {Li, Peiyao and Castelo, Noah and Katona, Zsolt and Sarvary, Miklos},
  year = {2024},
  month = jan,
  journal = {Marketing Science},
  volume = {43},
  number = {2},
  pages = {254--266},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0454},
  urldate = {2024-05-13},
  abstract = {This paper explores the potential of large language models (LLMs) to substitute for human participants in market research. Such LLMs can be used to generate text given a prompt. We argue that perceptual analysis is a particularly promising use case for such automated market research for certain product categories. The proposed new method generates outputs that closely match those generated from human surveys: agreement rates between human- and LLM- generated data sets reach over 75\%. Moreover, this applies for perceptual analysis based on both brand similarity measures and product attribute ratings. The paper demonstrates that, for some categories, this new method of fully or partially automated market research will increase the efficiency of market research by meaningfully speeding up the process and potentially reducing the cost. Further results also suggest that with an ever larger training corpus applied to large language models, LLM-based market research will be applicable to answer more nuanced questions based on demographic variables or contextual variation that would be prohibitively expensive or infeasible with human respondents. History: Catherine Tucker served as the senior editor. This paper was accepted through the Marketing Science: Frontiers review process. Funding: This work was supported by the Social Sciences and Humanities Research Council of Canada [Grant 430-2021-00057]. Supplemental Material: The online appendix and data files are available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2023.0454.},
  keywords = {artificial Intelligence,large language model,market research,natural language processing,notion,perceptual maps},
  file = {/Users/hoener/Zotero/storage/HHANZHZZ/Li et al. - 2024 - Frontiers Determining the Validity of Large Langu.pdf}
}

@article{liFrontiersDeterminingValidity2024b,
  title = {Frontiers: {{Determining}} the {{Validity}} of {{Large Language Models}} for {{Automated Perceptual Analysis}}},
  shorttitle = {Frontiers},
  author = {Li, Peiyao and Castelo, Noah and Katona, Zsolt and Sarvary, Miklos},
  year = {2024},
  month = jan,
  journal = {Marketing Science},
  volume = {43},
  number = {2},
  pages = {254--266},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0454},
  urldate = {2024-06-04},
  abstract = {This paper explores the potential of large language models (LLMs) to substitute for human participants in market research. Such LLMs can be used to generate text given a prompt. We argue that perceptual analysis is a particularly promising use case for such automated market research for certain product categories. The proposed new method generates outputs that closely match those generated from human surveys: agreement rates between human- and LLM- generated data sets reach over 75\%. Moreover, this applies for perceptual analysis based on both brand similarity measures and product attribute ratings. The paper demonstrates that, for some categories, this new method of fully or partially automated market research will increase the efficiency of market research by meaningfully speeding up the process and potentially reducing the cost. Further results also suggest that with an ever larger training corpus applied to large language models, LLM-based market research will be applicable to answer more nuanced questions based on demographic variables or contextual variation that would be prohibitively expensive or infeasible with human respondents.History: Catherine Tucker served as the senior editor. This paper was accepted through the Marketing Science: Frontiers review process.Funding: This work was supported by the Social Sciences and Humanities Research Council of Canada [Grant 430-2021-00057].Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0454.},
  keywords = {artificial Intelligence,large language model,market research,natural language processing,perceptual maps},
  file = {/Users/hoener/Zotero/storage/MEDC3Y49/Li et al. - 2024 - Frontiers Determining the Validity of Large Langu.pdf}
}

@techreport{ludwigMachineLearningTool2023,
  title = {Machine {{Learning}} as a {{Tool}} for {{Hypothesis Generation}}},
  author = {Ludwig, Jens and Mullainathan, Sendhil},
  year = {2023},
  month = mar,
  number = {w31017},
  pages = {w31017},
  address = {Cambridge, MA},
  institution = {National Bureau of Economic Research},
  doi = {10.3386/w31017},
  urldate = {2023-10-12},
  langid = {english},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/YHISPA8M/Ludwig and Mullainathan - 2023 - Machine Learning as a Tool for Hypothesis Generati.pdf}
}

@article{maMachineLearningAI2020,
  title = {Machine Learning and {{AI}} in Marketing -- {{Connecting}} Computing Power to Human Insights},
  author = {Ma, Liye and Sun, Baohong},
  year = {2020},
  month = sep,
  journal = {International Journal of Research in Marketing},
  volume = {37},
  number = {3},
  pages = {481--504},
  issn = {0167-8116},
  doi = {10.1016/j.ijresmar.2020.04.005},
  urldate = {2024-06-04},
  abstract = {Artificial intelligence (AI) agents driven by machine learning algorithms are rapidly transforming the business world, generating heightened interest from researchers. In this paper, we review and call for marketing research to leverage machine learning methods. We provide an overview of common machine learning tasks and methods, and compare them with statistical and econometric methods that marketing researchers traditionally use. We argue that machine learning methods can process large-scale and unstructured data, and have flexible model structures that yield strong predictive performance. Meanwhile, such methods may lack model transparency and interpretability. We discuss salient AI-driven industry trends and practices, and review the still nascent academic marketing literature which uses machine learning methods. More importantly, we present a unified conceptual framework and a multi-faceted research agenda. From five key aspects of empirical marketing research: method, data, usage, issue, and theory, we propose a number of research priorities, including extending machine learning methods and using them as core components in marketing research, using the methods to extract insights from large-scale unstructured, tracking, and network data, using them in transparent fashions for descriptive, causal, and prescriptive analyses, using them to map out customer purchase journeys and develop decision-support capabilities, and connecting the methods to human insights and marketing theories. Opportunities abound for machine learning methods in marketing, and we hope our multi-faceted research agenda will inspire more work in this exciting area.},
  keywords = {Artificial intelligence (AI),Big data,Digital marketing,Interpretation,Machine learning,Marketing theory,Network,Prediction,Tracking data,Unstructured data},
  file = {/Users/hoener/Zotero/storage/QX824U72/S0167811620300410.html}
}

@misc{MegaSynIntegratingGenerative,
  title = {{{MegaSyn}}: {{Integrating Generative Molecular Design}}, {{Automated Analog Designer}}, and {{Synthetic Viability Prediction}} {\textbar} {{ACS Omega}}},
  urldate = {2024-04-07},
  howpublished = {https://pubs.acs.org/doi/full/10.1021/acsomega.2c01404},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/TNFMQTH7/acsomega.html}
}

@misc{metaMetaLlama,
  title = {Meta {{Llama}} 3 --- Llama.Meta.Com}
}

@inproceedings{NEURIPS2022_b1efde53,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {27730--27744},
  publisher = {Curran Associates, Inc.}
}

@article{ouyangTrainingLanguageModels2022,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F. and Leike, Jan and Lowe, Ryan},
  year = {2022},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {27730--27744},
  urldate = {2024-06-04},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/5SYHPV6I/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf}
}

@article{puntoniConsumersArtificialIntelligence2021b,
  title = {Consumers and {{Artificial Intelligence}}: {{An Experiential Perspective}}},
  shorttitle = {Consumers and {{Artificial Intelligence}}},
  author = {Puntoni, Stefano and Reczek, Rebecca Walker and Giesler, Markus and Botti, Simona},
  year = {2021},
  month = jan,
  journal = {Journal of Marketing},
  volume = {85},
  number = {1},
  pages = {131--151},
  publisher = {SAGE Publications Inc},
  issn = {0022-2429},
  doi = {10.1177/0022242920953847},
  urldate = {2024-06-04},
  abstract = {Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations' investments into AI and to lay out an agenda for future research.},
  langid = {english}
}

@article{radford2018improving,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year = {2018},
  publisher = {OpenAI},
  keywords = {notion}
}

@article{reimersSentenceBERTSentenceEmbeddings2019,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1908.10084},
  urldate = {2023-07-09},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  copyright = {Creative Commons Attribution Share Alike 4.0 International},
  keywords = {Computation and Language (cs.CL),embedding,FOS: Computer and information sciences,llm,notion}
}

@article{shenBaselineNeedsMore2018,
  title = {Baseline {{Needs More Love}}: {{On Simple Word-Embedding-Based Models}} and {{Associated Pooling Mechanisms}}},
  shorttitle = {Baseline {{Needs More Love}}},
  author = {Shen, Dinghan and Wang, Guoyin and Wang, Wenlin and Min, Martin Renqiang and Su, Qinliang and Zhang, Yizhe and Li, Chunyuan and Henao, Ricardo and Carin, Lawrence},
  year = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1805.09843},
  urldate = {2023-07-09},
  abstract = {Many deep learning architectures have been proposed to model the compositionality in text sequences, requiring a substantial number of parameters and expensive computations. However, there has not been a rigorous evaluation regarding the added value of sophisticated compositional functions. In this paper, we conduct a point-by-point comparative study between Simple Word-Embedding-based Models (SWEMs), consisting of parameter-free pooling operations, relative to word-embedding-based RNN/CNN models. Surprisingly, SWEMs exhibit comparable or even superior performance in the majority of cases considered. Based upon this understanding, we propose two additional pooling strategies over learned word embeddings: (i) a max-pooling operation for improved interpretability; and (ii) a hierarchical pooling operation, which preserves spatial (n-gram) information within text sequences. We present experiments on 17 datasets encompassing three tasks: (i) (long) document classification; (ii) text sequence matching; and (iii) short text tasks, including classification and tagging. The source code and datasets can be obtained from https:// github.com/dinghanshen/SWEM.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences,Machine Learning (cs.LG),notion}
}

@article{tatsunorihashimotoUnifyingHumanStatistical2019,
  title = {Unifying {{Human}} and {{Statistical Evaluation}} for {{Natural Language Generation}}},
  author = {{Tatsunori Hashimoto} and Hashimoto, Tatsunori B. and {Hugh Zhang} and Zhang, Hugh and {Percy Liang} and Liang, Percy},
  year = {2019},
  month = apr,
  journal = {arXiv: Computation and Language},
  abstract = {How can we measure whether a natural language generation system produces both high quality and diverse outputs? Human evaluation captures quality but not diversity, as it does not catch models that simply plagiarize from the training set. On the other hand, statistical evaluation (i.e., perplexity) captures diversity but not quality, as models that occasionally emit low quality samples would be insufficiently penalized. In this paper, we propose a unified framework which evaluates both diversity and quality, based on the optimal error rate of predicting whether a sentence is human- or machine-generated. We demonstrate that this error rate can be efficiently estimated by combining human and statistical evaluation, using an evaluation metric which we call HUSE. On summarization and chit-chat dialogue, we show that (i) HUSE detects diversity defects which fool pure human evaluation and that (ii) techniques such as annealing for improving quality actually decrease HUSE due to decreased diversity.},
  keywords = {evaluation,generation,Generative AI,llm},
  annotation = {MAG ID: 2941169998}
}

@article{tomasmikolovDistributedRepresentationsWords2013,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  author = {{Tom{\'a}{\v s} Mikolov} and Mikolov, Tomas and {Ilya Sutskever} and Sutskever, Ilya and {Kai Chen} and Chen, Kai and {Kai Chen} and {Greg S. Corrado} and Corrado, Greg S. and {Jeff Dean} and Dean, Jeffrey},
  year = {2013},
  month = dec,
  volume = {26},
  pages = {3111--3119},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
  annotation = {MAG ID: 2153579005}
}

@article{tomasmikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {{Tom{\'a}{\v s} Mikolov} and Mikolov, Tomas and {Kai Chen} and Chen, Kai and {Kai Chen} and {Greg S. Corrado} and Corrado, Greg S. and {J. Michael Dean} and Dean, Jeffrey},
  year = {2013},
  month = jan,
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  annotation = {MAG ID: 1614298861}
}

@article{tuckerSocialNetworksPersonalized2014,
  title = {Social {{Networks}}, {{Personalized Advertising}}, and {{Privacy Controls}}},
  author = {Tucker, Catherine E.},
  year = {2014},
  month = oct,
  journal = {Journal of Marketing Research},
  volume = {51},
  number = {5},
  pages = {546--562},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1509/jmr.10.0355},
  urldate = {2024-06-04},
  abstract = {This article investigates how Internet users' perceptions of control over their personal information affect how likely they are to click on online advertising on a social networking website. The analysis uses data from a randomized field experiment that examined the effectiveness of personalizing ad text with user-posted personal information relative to generic text. The website gave users more control over their personally identifiable information in the middle of the field test. However, the website did not change how advertisers used data to target and personalize ads. Before the policy change, personalized ads did not perform particularly well. However, after this enhancement of perceived control over privacy, users were nearly twice as likely to click on personalized ads. Ads that targeted but did not use personalized text remained unchanged in effectiveness. The increase in effectiveness was larger for ads that used more unique private information to personalize their message and for target groups that were more likely to use opt-out privacy settings.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/J8YUTM46/Tucker - 2014 - Social Networks, Personalized Advertising, and Pri.pdf}
}

@article{vaswani2017attention,
  title = {Attention Is All You Need},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30},
  keywords = {notion}
}

@misc{wangDisentangledRepresentationLearning2024,
  title = {Disentangled {{Representation Learning}}},
  author = {Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  year = {2024},
  month = may,
  number = {arXiv:2211.11695},
  eprint = {2211.11695},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.11695},
  urldate = {2024-05-29},
  abstract = {Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, and data mining. In this article, we comprehensively investigate DRL from various aspects including motivations, definitions, methodologies, evaluations, applications, and model designs. We first present two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition for disentangled representation learning. We further categorize the methodologies for DRL into four groups from the following perspectives, the model type, representation structure, supervision signal, and independence assumption. We also analyze principles to design different DRL models that may benefit different tasks in practical applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this work may provide insights for promoting the DRL research in the community.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/BJKSADUV/Wang et al. - 2024 - Disentangled Representation Learning.pdf;/Users/hoener/Zotero/storage/J2NTYGXR/2211.html}
}

@misc{wangDisentangledRepresentationLearning2024a,
  title = {Disentangled {{Representation Learning}}},
  author = {Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  year = {2024},
  month = may,
  number = {arXiv:2211.11695},
  eprint = {2211.11695},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-29},
  abstract = {Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, and data mining. In this article, we comprehensively investigate DRL from various aspects including motivations, definitions, methodologies, evaluations, applications, and model designs. We first present two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition for disentangled representation learning. We further categorize the methodologies for DRL into four groups from the following perspectives, the model type, representation structure, supervision signal, and independence assumption. We also analyze principles to design different DRL models that may benefit different tasks in practical applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this work may provide insights for promoting the DRL research in the community.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/AI7GI9G5/Wang et al. - 2024 - Disentangled Representation Learning.pdf}
}

@article{yinhanliuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  author = {{Yinhan Liu} and Liu, Yinhan and {Myle Ott} and Ott, Myle and {Naman Goyal} and Goyal, Naman and {Jingfei Du} and Du, Jingfei and {Mandar Joshi} and Joshi, Mandar and {Danqi Chen} and Chen, Danqi and {Omer Levy} and Levy, Omer and {Mike Lewis} and Lewis, Michael and {Michael Lewis} and {Michael Lewis} and Lewis, Mike and {Luke Zettlemoyer} and Zettlemoyer, Luke and {Veselin Stoyanov} and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  journal = {arXiv: Computation and Language},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  annotation = {MAG ID: 2965373594}
}
