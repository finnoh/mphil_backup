@article{ariholtzmanCuriousCaseNeural2020,
  title = {The {{Curious Case}} of {{Neural Text Degeneration}}},
  author = {{Ari Holtzman} and Holtzman, Ari and {Jan Buys} and Buys, Jan and {Leo Du} and Du, Leo and {Maxwell Forbes} and Forbes, Maxwell and {Yejin Choi} and Choi, Yejin},
  year = {2020},
  month = apr,
  abstract = {Despite considerable advances in neural language modeling, it remains an open question what the best decoding strategy is for text generation from a language model (e.g. to generate a story). The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, maximization-based decoding methods such as beam search lead to degeneration --- output text that is bland, incoherent, or gets stuck in repetitive loops. To address this we propose Nucleus Sampling, a simple but effective method to draw considerably higher quality text out of neural language models. Our approach avoids text degeneration by truncating the unreliable tail of the probability distribution, sampling from the dynamic nucleus of tokens containing the vast majority of the probability mass. To properly examine current maximization-based and stochastic decoding methods, we compare generations from each of these methods to the distribution of human text along several axes such as likelihood, diversity, and repetition. Our results show that (1) maximization is an inappropriate decoding objective for open-ended text generation, (2) the probability distributions of the best current language models have an unreliable tail which needs to be truncated during generation and (3) Nucleus Sampling is the best decoding strategy for generating long-form text that is both high-quality --- as measured by human evaluation --- and as diverse as human-written text.},
  keywords = {generation,Generative AI,llm},
  annotation = {MAG ID: 2996287690}
}

@misc{baLayerNormalization2016,
  title = {Layer {{Normalization}}},
  author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  year = {2016},
  month = jul,
  number = {arXiv:1607.06450},
  eprint = {1607.06450},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-06-17},
  abstract = {Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/hoener/Zotero/storage/AJ9HIUAP/Ba et al. - 2016 - Layer Normalization.pdf}
}

@article{beckerDoesItPay2019,
  title = {Does {{It Pay}} to {{Be Real}}? {{Understanding Authenticity}} in {{TV Advertising}}},
  shorttitle = {Does {{It Pay}} to {{Be Real}}?},
  author = {Becker, Maren and Wiegand, Nico and Reinartz, Werner J.},
  year = {2019},
  month = jan,
  journal = {Journal of Marketing},
  volume = {83},
  number = {1},
  pages = {24--50},
  publisher = {SAGE Publications Inc},
  issn = {0022-2429},
  doi = {10.1177/0022242918815880},
  urldate = {2024-06-07},
  abstract = {Marketing managers and creatives alike believe that authenticity is an essential element for effective advertising. However, no common understanding of authenticity in advertising exists, and empirical knowledge about its impact on consumer behavior is limited. In this study, the authors use a comprehensive literature review and qualitative studies to identify four dimensions of authenticity in an advertising context. By examining 323 television ads across 67 brands and four years, they investigate these dimensions' effects on the sales performance of advertised products. Because the impact of authenticity may depend on brand or product characteristics, the authors also analyze how these effects vary with brand size or across hedonic and utilitarian products. The results suggest that authenticity influences consumer behavior in a more nuanced manner than previously recognized. For instance, whereas an ad congruent with the brand's essence has a positive effect on sales in most cases, an overly honest advertising message can actually hurt performance; the latter is true especially for hedonic products, for which consumers rely more on subjective information when making purchase decisions.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/5JVB9HW6/Becker et al. - 2019 - Does It Pay to Be Real Understanding Authenticity.pdf}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? 🦜},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  month = mar,
  pages = {610--623},
  publisher = {ACM},
  address = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  urldate = {2023-06-26},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/I8MP3WNP/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf}
}

@article{bergerUnitingTribesUsing2020a,
  title = {Uniting the {{Tribes}}: {{Using Text}} for {{Marketing Insight}}},
  shorttitle = {Uniting the {{Tribes}}},
  author = {Berger, Jonah and Humphreys, Ashlee and Ludwig, Stephan and Moe, Wendy W. and Netzer, Oded and Schweidel, David A.},
  year = {2020},
  month = jan,
  journal = {Journal of Marketing},
  volume = {84},
  number = {1},
  pages = {1--25},
  publisher = {SAGE Publications Inc},
  issn = {0022-2429},
  doi = {10.1177/0022242919873106},
  urldate = {2024-06-21},
  abstract = {Words are part of almost every marketplace interaction. Online reviews, customer service calls, press releases, marketing communications, and other interactions create a wealth of textual data. But how can marketers best use such data? This article provides an overview of automated textual analysis and details how it can be used to generate marketing insights. The authors discuss how text reflects qualities of the text producer (and the context in which the text was produced) and impacts the audience or text recipient. Next, they discuss how text can be a powerful tool both for prediction and for understanding (i.e., insights). Then, the authors overview methodologies and metrics used in text analysis, providing a set of guidelines and procedures. Finally, they further highlight some common metrics and challenges and discuss how researchers can address issues of internal and external validity. They conclude with a discussion of potential areas for future work. Along the way, the authors note how textual analysis can unite the tribes of marketing. While most marketing problems are interdisciplinary, the field is often fragmented. By involving skills and ideas from each of the subareas of marketing, text analysis has the potential to help unite the field with a common set of tools and approaches.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/6FWXMGU3/Berger et al. - 2020 - Uniting the Tribes Using Text for Marketing Insig.pdf}
}

@article{bergerUnitingTribesUsing2020b,
  title = {Uniting the {{Tribes}}: {{Using Text}} for {{Marketing Insight}}},
  shorttitle = {Uniting the {{Tribes}}},
  author = {Berger, Jonah and Humphreys, Ashlee and Ludwig, Stephan and Moe, Wendy W. and Netzer, Oded and Schweidel, David A.},
  year = {2020},
  month = jan,
  journal = {Journal of Marketing},
  volume = {84},
  number = {1},
  pages = {1--25},
  publisher = {SAGE Publications Inc},
  issn = {0022-2429},
  doi = {10.1177/0022242919873106},
  urldate = {2024-06-21},
  abstract = {Words are part of almost every marketplace interaction. Online reviews, customer service calls, press releases, marketing communications, and other interactions create a wealth of textual data. But how can marketers best use such data? This article provides an overview of automated textual analysis and details how it can be used to generate marketing insights. The authors discuss how text reflects qualities of the text producer (and the context in which the text was produced) and impacts the audience or text recipient. Next, they discuss how text can be a powerful tool both for prediction and for understanding (i.e., insights). Then, the authors overview methodologies and metrics used in text analysis, providing a set of guidelines and procedures. Finally, they further highlight some common metrics and challenges and discuss how researchers can address issues of internal and external validity. They conclude with a discussion of potential areas for future work. Along the way, the authors note how textual analysis can unite the tribes of marketing. While most marketing problems are interdisciplinary, the field is often fragmented. By involving skills and ideas from each of the subareas of marketing, text analysis has the potential to help unite the field with a common set of tools and approaches.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/56S9D4IJ/Berger et al. - 2020 - Uniting the Tribes Using Text for Marketing Insig.pdf}
}

@misc{brandUsingGPTMarket2023a,
  type = {{{SSRN Scholarly Paper}}},
  title = {Using {{GPT}} for {{Market Research}}},
  author = {Brand, James and Israeli, Ayelet and Ngwe, Donald},
  year = {2023},
  month = mar,
  number = {4395751},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4395751},
  urldate = {2024-06-04},
  abstract = {Large language models (LLMs) have quickly become popular as labor-augmenting tools for programming, writing, and many other processes that benefit from quick text generation. In this paper we explore the uses and benefits of LLMs for researchers and practitioners who aim to understand consumer preferences. We focus on the distributional nature of LLM responses, and query the Generative Pre-trained Transformer 3.5 (GPT-3.5) model to generate hundreds of survey responses to each prompt. We offer two sets of results to illustrate our approach and assess it. First, we show that GPT-3.5, a widely-used LLM, responds to sets of survey questions in ways that are consistent with economic theory and well-documented patterns of consumer behavior, including downward-sloping demand curves and state dependence. Second, we show that estimates of willingness-to-pay for products and features generated by GPT-3.5 are of realistic magnitudes and match estimates from a recent study that elicited preferences from human consumers. We also offer preliminary guidelines for how best to query information from GPT-3.5 for marketing purposes and discuss potential limitations.},
  langid = {english},
  keywords = {AI,Conjoint,Consumer preferences,Generative Pre-trained Transformer (GPT),Large language models (LLMs),Market research},
  file = {/Users/hoener/Zotero/storage/UCA8AY2P/Brand et al. - 2023 - Using GPT for Market Research.pdf}
}

@article{burnap2023product,
  title = {Product Aesthetic Design: {{A}} Machine Learning Augmentation},
  author = {Burnap, Alex and Hauser, John R and Timoshenko, Artem},
  year = {2023},
  journal = {Marketing Science},
  volume = {42},
  number = {6},
  pages = {1029--1056},
  publisher = {INFORMS},
  file = {/Users/hoener/Downloads/burnap-et-al-2023-product-aesthetic-design-a-machine-learning-augmentation.pdf}
}

@article{cathyoneilWeaponsMathDestruction2016,
  title = {Weapons of {{Math Destruction}}: {{How Big Data Increases Inequality}} and {{Threatens Democracy}}},
  author = {{Cathy O'Neil} and O'Neil, Cathy and {Cathy O'Neil}},
  year = {2016},
  month = sep,
  abstract = {A former Wall Street quant sounds an alarm on the mathematical models that pervade modern life and threaten to rip apart our social fabricWe live in the age of the algorithm. Increasingly, the decisions that affect our liveswhere we go to school, whether we get a car loan, how much we pay for health insuranceare being made not by humans, but by mathematical models. In theory, this should lead to greater fairness: Everyone is judged according to the same rules, and bias is eliminated. But as Cathy ONeil reveals in this urgent and necessary book, the opposite is true. The models being used today are opaque, unregulated, and uncontestable, even when theyre wrong. Most troubling, they reinforce discrimination: If a poor student cant get a loan because a lending model deems him too risky (by virtue of his zip code), hes then cut off from the kind of education that could pull him out of poverty, and a vicious spiral ensues. Models are propping up the lucky and punishing the downtrodden, creating a toxic cocktail for democracy. Welcome to the dark side of Big Data. Tracing the arc of a persons life, ONeil exposes the black box models that shape our future, both as individuals and as a society. These weapons of math destruction score teachers and students, sort rsums, grant (or deny) loans, evaluate workers, target voters, set parole, and monitor our health. ONeil calls on modelers to take more responsibility for their algorithms and on policy makers to regulate their use. But in the end, its up to us to become more savvy about the models that govern our lives. This important book empowers us to ask the tough questions, uncover the truth, and demand change.},
  annotation = {MAG ID: 2573660794}
}

@incollection{chakrabortyAbstractiveSummarizationEvaluation2024,
  title = {Abstractive {{Summarization Evaluation}} for {{Prompt Engineering}}},
  booktitle = {Advances in {{Visual Informatics}}},
  author = {Chakraborty, Shayak and Pakray, Partha},
  editor = {Badioze Zaman, Halimah and Robinson, Peter and Smeaton, Alan F. and De Oliveira, Renato Lima and J{\o}rgensen, Bo N{\o}rregaard and K. Shih, Timothy and Abdul Kadir, Rabiah and Mohamad, Ummul Hanan and Ahmad, Mohammad Nazir},
  year = {2024},
  volume = {14322},
  pages = {629--640},
  publisher = {Springer Nature Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-99-7339-2_50},
  urldate = {2024-06-13},
  isbn = {978-981-9973-38-5 978-981-9973-39-2},
  langid = {english}
}

@article{chandraPersonalizationPersonalizedMarketing2022,
  title = {Personalization in Personalized Marketing: {{Trends}} and Ways Forward},
  shorttitle = {Personalization in Personalized Marketing},
  author = {Chandra, Shobhana and Verma, Sanjeev and Lim, Weng Marc and Kumar, Satish and Donthu, Naveen},
  year = {2022},
  journal = {Psychology \& Marketing},
  volume = {39},
  number = {8},
  pages = {1529--1562},
  issn = {1520-6793},
  doi = {10.1002/mar.21670},
  urldate = {2024-06-04},
  abstract = {In marketing, personalization is the action of designing and producing in ways that resonate with customer preferences. Content and products that are personalized according to customer preferences can reduce customer fatigue and time in making choices, thereby decreasing their cognitive load. Despite its importance, the literature on personalized marketing remains fragmented due to the absence of a comprehensive review that consolidates the intellectual structure of the field. This study bridges this knowledge gap through a bibliometric review using performance analysis and science mapping. Through a comprehensive review of 383 publications, this study reveals the publication and citation trends, the most prolific authors, journals, and publications, and six major themes (i.e., personalized recommendation, personalized relationship, personalization--privacy paradox, personalized advertising, personalization concept and discourse in marketing, and customer insights in personalized marketing) that characterize the body of knowledge of personalized marketing. The study concludes with future research directions as ways forward for personalized marketing, wherein a focus on new-age technologies involving artificial intelligence, big data, blockchain, internet of things, and wearables is encouraged to explore new ways to curate personalized experiences across online and offline channels.},
  copyright = {{\copyright} 2022 The Authors. Psychology \& Marketing published by Wiley Periodicals LLC.},
  langid = {english},
  keywords = {advertising,bibliometric,customer insight,paradox,personalization,personalized marketing,privacy,recommendation,relationship,review,trends,ways forward}
}

@article{coyleRiseAICopilots2023,
  title = {The Rise of {{AI}} Copilots: {{How LLMs}} Turn Data into Actions, Advance the Business Intelligence Industry and Make Data Accessible Company-Wide},
  shorttitle = {The Rise of {{AI}} Copilots},
  author = {Coyle, Jeff and Jeske, Stephen},
  year = {2023},
  month = dec,
  journal = {Applied Marketing Analytics},
  volume = {9},
  number = {3},
  pages = {207--214},
  abstract = {AI-powered collaboration is quickly advancing due to a convergence of technologies like large language models and language model programming. These developments have spawned the rise of AI (artificial intelligence) copilots, which are changing the way marketing analysts make decisions and boost productivity. This paper explores the capabilities of AI copilots and delves into the challenges, ethical considerations and data privacy issues that come with their adoption. It discusses real-world applications and future trends in the AI copilot landscape. The paper also emphasises the importance of data integration and personalisation in marketing strategies and offers insights into training and skill development for effective collaboration with AI copilots. This comprehensive analysis aims to equip marketing analytics professionals for the future of AI-powered collaboration.},
  keywords = {AI-powered collaborator,artificial intelligence copilot,knowledge graph,language model query language,large language model}
}

@article{daiFrontiersWhichFirms2023,
  title = {Frontiers: {{Which Firms Gain}} from {{Digital Advertising}}? {{Evidence}} from a {{Field Experiment}}},
  shorttitle = {Frontiers},
  author = {Dai, Weijia and Kim, Hyunjin and Luca, Michael},
  year = {2023},
  month = may,
  journal = {Marketing Science},
  volume = {42},
  number = {3},
  pages = {429--439},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.1436},
  urldate = {2024-06-06},
  abstract = {Measuring the returns of advertising opportunities continues to be a challenge for many businesses. We design and run a field experiment on a large review platform across 18,294 firms in the restaurant industry to understand which types of businesses gain more from digital advertising. We randomly assign 7,209 restaurants to freely receive the platform's standard ads package for three months. The scale of the experiment gives us a unique opportunity to assess the heterogeneity in advertising effectiveness across a variety of business attributes. We find that restaurants that receive advertising observe on average a 7\%--19\% increase in a wide range of purchase intention outcomes, as well as a 5\% increase in customer reviews. We find that gains are heterogeneous across firms, with independent and higher-rated businesses observing larger gains, as well as those with more reviews and higher pre-experiment organic traffic.History: Olivier Toubia served as the senior editor for this article. This paper was accepted through the Marketing Science: Frontiers review process.Supplemental Material: The data and e-companion are available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2023.1436.},
  keywords = {advertising,field experiments,Google Scholar,restaurants,retail chains},
  file = {/Users/hoener/Zotero/storage/GZMWAA47/Dai et al. - 2023 - Frontiers Which Firms Gain from Digital Advertisi.pdf}
}

@article{daiFrontiersWhichFirms2023a,
  title = {Frontiers: {{Which Firms Gain}} from {{Digital Advertising}}? {{Evidence}} from a {{Field Experiment}}},
  shorttitle = {Frontiers},
  author = {Dai, Weijia and Kim, Hyunjin and Luca, Michael},
  year = {2023},
  month = may,
  journal = {Marketing Science},
  volume = {42},
  number = {3},
  pages = {429--439},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.1436},
  urldate = {2024-06-06},
  abstract = {Measuring the returns of advertising opportunities continues to be a challenge for many businesses. We design and run a field experiment on a large review platform across 18,294 firms in the restaurant industry to understand which types of businesses gain more from digital advertising. We randomly assign 7,209 restaurants to freely receive the platform's standard ads package for three months. The scale of the experiment gives us a unique opportunity to assess the heterogeneity in advertising effectiveness across a variety of business attributes. We find that restaurants that receive advertising observe on average a 7\%--19\% increase in a wide range of purchase intention outcomes, as well as a 5\% increase in customer reviews. We find that gains are heterogeneous across firms, with independent and higher-rated businesses observing larger gains, as well as those with more reviews and higher pre-experiment organic traffic.History: Olivier Toubia served as the senior editor for this article. This paper was accepted through the Marketing Science: Frontiers review process.Supplemental Material: The data and e-companion are available at https://doi.org/10.1287/mksc.2023.1436.},
  keywords = {advertising,field experiments,Google Scholar,restaurants,retail chains},
  file = {/Users/hoener/Zotero/storage/QCQJ5ZMR/Dai et al. - 2023 - Frontiers Which Firms Gain from Digital Advertisi.pdf}
}

@article{de2021survey,
  title = {A Survey on Text Generation Using Generative Adversarial Networks},
  author = {De Rosa, Gustavo H and Papa, Jo{\~a}o P},
  year = {2021},
  journal = {Pattern Recognition},
  volume = {119},
  pages = {108098},
  publisher = {Elsevier}
}

@article{defreitasChatbotsMentalHealth,
  title = {Chatbots and Mental Health: {{Insights}} into the Safety of Generative {{AI}}},
  shorttitle = {Chatbots and Mental Health},
  author = {De Freitas, Julian and U{\u g}uralp, Ahmet Kaan and {O{\u g}uz-U{\u g}uralp}, Zeliha and Puntoni, Stefano},
  journal = {Journal of Consumer Psychology},
  volume = {n/a},
  number = {n/a},
  issn = {1532-7663},
  doi = {10.1002/jcpy.1393},
  urldate = {2024-06-04},
  abstract = {Chatbots are now able to engage in sophisticated conversations with consumers. Due to the ``black box'' nature of the algorithms, it is impossible to predict in advance how these conversations will unfold. Behavioral research provides little insight into potential safety issues emerging from the current rapid deployment of this technology at scale. We begin to address this urgent question by focusing on the context of mental health and ``companion AI'': Applications designed to provide consumers with synthetic interaction partners. Studies 1a and 1b present field evidence: Actual consumer interactions with two different companion AIs. Study 2 reports an extensive performance test of several commercially available companion AIs. Study 3 is an experiment testing consumer reaction to risky and unhelpful chatbot responses. The findings show that (1) mental health crises are apparent in a nonnegligible minority of conversations with users; (2) companion AIs are often unable to recognize, and respond appropriately to, signs of distress; and (3) consumers display negative reactions to unhelpful and risky chatbot responses, highlighting emerging reputational risks for generative AI companies.},
  copyright = {{\copyright} 2023 Society for Consumer Psychology.},
  langid = {english},
  keywords = {artificial intelligence,chatbots,ethics,generative AI,large language models,mental health},
  file = {/Users/hoener/Zotero/storage/E8DWL3QX/De Freitas et al. - Chatbots and mental health Insights into the safe.pdf}
}

@article{derosaSurveyTextGeneration2021,
  title = {A Survey on Text Generation Using Generative Adversarial Networks},
  author = {{de Rosa}, Gustavo Henrique and Papa, Jo{\~a}o Paulo},
  year = {2021},
  month = nov,
  journal = {Pattern Recognition},
  volume = {119},
  eprint = {2212.11119},
  primaryclass = {cs},
  pages = {108098},
  issn = {00313203},
  doi = {10.1016/j.patcog.2021.108098},
  urldate = {2024-06-07},
  abstract = {This work presents a thorough review concerning recent studies and text generation advancements using Generative Adversarial Networks. The usage of adversarial learning for text generation is promising as it provides alternatives to generate the so-called ``natural'' language. Nevertheless, adversarial text generation is not a simple task as its foremost architecture, the Generative Adversarial Networks, were designed to cope with continuous information (image) instead of discrete data (text). Thus, most works are based on three possible options, i.e., Gumbel-Softmax differentiation, Reinforcement Learning, and modified training objectives. All alternatives are reviewed in this survey as they present the most recent approaches for generating text using adversarial-based techniques. The selected works were taken from renowned databases, such as Science Direct, IEEEXplore, Springer, Association for Computing Machinery, and arXiv, whereas each selected work has been critically analyzed and assessed to present its objective, methodology, and experimental results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/VU88DM2R/de Rosa and Papa - 2021 - A survey on text generation using generative adver.pdf}
}

@article{devlinBERTPretrainingDeep2018,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1810.04805},
  urldate = {2023-07-09},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Computation and Language (cs.CL),embedding,FOS: Computer and information sciences,notion},
  file = {/Users/hoener/Downloads/1810.04805v2.pdf}
}

@article{diederikp.kingmaAdamMethodStochastic2014,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  author = {{Diederik P. Kingma} and Kingma, Diederik P. and {Jimmy Ba} and Ba, Jimmy},
  year = {2014},
  month = dec,
  journal = {arXiv: Learning},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords = {optimization},
  annotation = {MAG ID: 1522301498}
}

@article{edelmanBrandingDigitalAge2010,
  title = {Branding in the {{Digital Age}}},
  author = {Edelman, David C},
  year = {2010},
  journal = {harvard business review},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/IDHN2TZM/Edelman - 2010 - Branding in the Digital Age.pdf}
}

@incollection{eggersChoiceBasedConjointAnalysis2022,
  title = {Choice-{{Based Conjoint Analysis}}},
  booktitle = {Handbook of {{Market Research}}},
  author = {Eggers, Felix and Sattler, Henrik and Teichert, Thorsten and V{\"o}lckner, Franziska},
  editor = {Homburg, Christian and Klarmann, Martin and Vomberg, Arnd},
  year = {2022},
  pages = {781--819},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-57413-4_23},
  urldate = {2024-05-28},
  isbn = {978-3-319-57411-0 978-3-319-57413-4},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/72IJB6VU/Eggers et al. - 2022 - Choice-Based Conjoint Analysis.pdf}
}

@article{emilyshengWomanWorkedBabysitter2019,
  title = {The {{Woman Worked}} as a {{Babysitter}}: {{On Biases}} in {{Language Generation}}},
  author = {{Emily Sheng} and Sheng, Emily and {Kai-Wei Chang} and Chang, Kai-Wei and {Kai-Wei Chang} and {Premkumar Natarajan} and Natarajan, Premkumar and {Premkumar Natarajan} and Natarajan, Premkumar and {Nanyun Peng} and Peng, Nanyun},
  year = {2019},
  month = nov,
  pages = {3405--3410},
  doi = {10.18653/v1/d19-1339},
  abstract = {We present a systematic study of biases in natural language generation (NLG) by analyzing text generated from prompts that contain mentions of different demographic groups. In this work, we introduce the notion of the regard towards a demographic, use the varying levels of regard towards different demographics as a defining metric for bias in NLG, and analyze the extent to which sentiment scores are a relevant proxy metric for regard. To this end, we collect strategically-generated text from language models and manually annotate the text with both sentiment and regard scores. Additionally, we build an automatic regard classifier through transfer learning, so that we can analyze biases in unseen text. Together, these methods reveal the extent of the biased nature of language model generations. Our analysis provides a study of biases in NLG, bias metrics and correlated human judgments, and empirical evidence on the usefulness of our annotated dataset.},
  keywords = {biases,ethics,llm},
  annotation = {MAG ID: 2971307358}
}

@inproceedings{feldmanUtilizingTextMining2015,
  title = {Utilizing {{Text Mining}} on {{Online Medical Forums}} to {{Predict Label Change}} Due to {{Adverse Drug Reactions}}},
  booktitle = {Proceedings of the 21th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Feldman, Ronen and Netzer, Oded and Peretz, Aviv and Rosenfeld, Binyamin},
  year = {2015},
  month = aug,
  series = {{{KDD}} '15},
  pages = {1779--1788},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2783258.2788608},
  urldate = {2024-06-20},
  abstract = {We present an end-to-end text mining methodology for relation extraction of adverse drug reactions (ADRs) from medical forums on the Web. Our methodology is novel in that it combines three major characteristics: (i) an underlying concept of using a head-driven phrase structure grammar (HPSG) based parser; (ii) domain-specific relation patterns, the acquisition of which is done primarily using unsupervised methods applied to a large, unlabeled text corpus; and (iii) automated post-processing algorithms for enhancing the set of extracted relations. We empirically demonstrate the ability of our proposed approach to predict ADRs prior to their reporting by the Food and Drug Administration (FDA). Put differently, we put our approach to a predictive test by demonstrating that our methodology can credibly point to ADRs that were not uncovered in clinical trials for evaluating new drugs that come to market but were only reported later on by the FDA as a label change.},
  isbn = {978-1-4503-3664-2},
  keywords = {adverse drug reactions,hpsg,medical forums,pharmaceutical drugs,text mining},
  file = {/Users/hoener/Zotero/storage/MZVE3W6H/Feldman et al. - 2015 - Utilizing Text Mining on Online Medical Forums to .pdf}
}

@article{goliFrontiersCanLarge2024,
  title = {Frontiers: {{Can Large Language Models Capture Human Preferences}}?},
  shorttitle = {Frontiers},
  author = {Goli, Ali and Singh, Amandeep},
  year = {2024},
  month = apr,
  journal = {Marketing Science},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0306},
  urldate = {2024-06-06},
  abstract = {We explore the viability of large language models (LLMs), specifically OpenAI's GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting preferences, with a focus on intertemporal choices. Leveraging the extensive literature on intertemporal discounting for benchmarking, we examine responses from LLMs across various languages and compare them with human responses, exploring preferences between smaller, sooner and larger, later rewards. Our findings reveal that both generative pretrained transformer (GPT) models demonstrate less patience than humans, with GPT-3.5 exhibiting a lexicographic preference for earlier rewards unlike human decision makers. Although GPT-4 does not display lexicographic preferences, its measured discount rates are still considerably larger than those found in humans. Interestingly, GPT models show greater patience in languages with weak future tense references, such as German and Mandarin, aligning with the existing literature that suggests a correlation between language structure and intertemporal preferences. We demonstrate how prompting GPT to explain its decisions, a procedure we term ``chain-of-thought conjoint,'' can mitigate, but does not eliminate, discrepancies between LLM and human responses. Although directly eliciting preferences using LLMs may yield misleading results, combining chain-of-thought conjoint with topic modeling aids in hypothesis generation, enabling researchers to explore the underpinnings of preferences. Chain-of-thought conjoint provides a structured framework for marketers to use LLMs to identify potential attributes or factors that can explain preference heterogeneity across different customers and contexts.History: Olivier Toubia served as the senior editor. This paper was accepted through the Marketing Science: Frontiers review process.Supplemental Material: The online appendix and data files are available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2023.0306.},
  keywords = {chain of thought,conjoint,decision making,intertemporal preferences,large language models},
  file = {/Users/hoener/Zotero/storage/MRIZMN28/Goli and Singh - 2024 - Frontiers Can Large Language Models Capture Human.pdf}
}

@book{goodfellowDeepLearning2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  abstract = {"Deep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and video games. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors"--Publisher's description},
  isbn = {978-0-262-33737-3},
  langid = {english},
  keywords = {notion},
  annotation = {OCLC: 1183962587},
  file = {/Users/hoener/Downloads/goodfellowDeepLearning2016.pdf}
}

@article{goodfellowGenerativeAdversarialNetworks2020,
  title = {Generative Adversarial Networks},
  author = {Goodfellow, Ian and {Pouget-Abadie}, Jean and Mirza, Mehdi and Xu, Bing and {Warde-Farley}, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  year = {2020},
  month = oct,
  journal = {Communications of the ACM},
  volume = {63},
  number = {11},
  pages = {139--144},
  issn = {0001-0782},
  doi = {10.1145/3422622},
  urldate = {2024-06-07},
  abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
  file = {/Users/hoener/Zotero/storage/3GJCV9NN/Goodfellow et al. - 2020 - Generative adversarial networks.pdf}
}

@article{guitartImpactInformationalEmotional2021,
  title = {The {{Impact}} of {{Informational}} and {{Emotional Television Ad Content}} on {{Online Search}} and {{Sales}}},
  author = {Guitart, Ivan A. and Stremersch, Stefan},
  year = {2021},
  month = apr,
  journal = {Journal of Marketing Research},
  volume = {58},
  number = {2},
  pages = {299--320},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1177/0022243720962505},
  urldate = {2024-06-07},
  abstract = {This article documents how informational and emotional appeals in more than 2,000 television ads for 144 car models, aired over four years, influence online search and sales. Increasing the emotional content of ads leads to increases in online search, but increasing the informational content does not. Both informational and emotional content positively influence sales. However, increases in informational content lead to more incremental sales for low-price and low-quality cars than for high-price and high-quality cars. In turn, increases in emotional content generate more incremental sales for high-price cars than for low-price cars. Analyses of the results suggest that managers of high-price and high-quality cars should prioritize emotional rather than informational content in ads. However, managers of low-price and low-quality cars should emphasize emotional content if their objective is to increase online search and informational content if their objective is to increase sales.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/DCEEJCEJ/Guitart and Stremersch - 2021 - The Impact of Informational and Emotional Televisi.pdf}
}

@article{haleemArtificialIntelligenceAI2022,
  title = {Artificial Intelligence ({{AI}}) Applications for Marketing: {{A}} Literature-Based Study},
  shorttitle = {Artificial Intelligence ({{AI}}) Applications for Marketing},
  author = {Haleem, Abid and Javaid, Mohd and Asim Qadri, Mohd and Pratap Singh, Ravi and Suman, Rajiv},
  year = {2022},
  month = jan,
  journal = {International Journal of Intelligent Networks},
  volume = {3},
  pages = {119--132},
  issn = {2666-6030},
  doi = {10.1016/j.ijin.2022.08.005},
  urldate = {2024-06-04},
  abstract = {Artificial Intelligence (AI) has vast potential in marketing. It aids in proliferating information and data sources, improving software's data management capabilities, and designing intricate and advanced algorithms. AI is changing the way brands and users interact with one another. The application of this technology is highly dependent on the nature of the website and the type of business. Marketers can now focus more on the customer and meet their needs in real time. By using AI, they can quickly determine what content to target customers and which channel to employ at what moment, thanks to the data collected and generated by its algorithms. Users feel at ease and are more inclined to buy what is offered when AI is used to personalise their experiences. AI tools can also be used to analyse the performance of a competitor's campaigns and reveal their customers' expectations. Machine Learning (ML) is a subset of AI that allows computers to analyse and interpret data without being explicitly programmed. Furthermore, ML assists humans in solving problems efficiently. The algorithm learns and improves performance and accuracy as more data is fed into the algorithm. For this research, relevant articles on AI in marketing are identified from Scopus, Google scholar, researchGate and other platforms. Then these articles were read, and the theme of the paper was developed. This paper attempts to review the role of AI in marketing. The specific applications of AI in various marketing segments and their transformations for marketing sectors are examined. Finally, critical applications of AI for marketing are recognised and analysed.},
  keywords = {Applications,Artificial intelligence (AI),Customer,Data analysis,Decision,Generative AI,Marketing},
  file = {/Users/hoener/Zotero/storage/3P7TFQ7I/S2666603022000136.html}
}

@incollection{hartmannNaturalLanguageProcessing2023,
  title = {Natural {{Language Processing}} in {{Marketing}}},
  booktitle = {Artificial {{Intelligence}} in {{Marketing}}},
  author = {Hartmann, Jochen and Netzer, Oded},
  editor = {Sudhir, K. and Toubia, Olivier},
  year = {2023},
  month = jan,
  series = {Review of {{Marketing Research}}},
  volume = {20},
  pages = {191--215},
  publisher = {Emerald Publishing Limited},
  doi = {10.1108/S1548-643520230000020011},
  urldate = {2024-06-21},
  abstract = {The increasing importance and proliferation of text data provide a unique opportunity and novel lens to study human communication across a myriad of business and marketing applications. For example, consumers compare and review products online, individuals interact with their voice assistants to search, shop, and express their needs, investors seek to extract signals from firms' press releases to improve their investment decisions, and firms analyze sales call transcripts to increase customer satisfaction and conversions. However, extracting meaningful information from unstructured text data is a nontrivial task. In this chapter, we review established natural language processing (NLP) methods for traditional tasks (e.g., LDA for topic modeling and lexicons for sentiment analysis and writing style extraction) and provide an outlook into the future of NLP in marketing, covering recent embedding-based approaches, pretrained language models, and transfer learning for novel tasks such as automated text generation and multi-modal representation learning. These emerging approaches allow the field to improve its ability to perform certain tasks that we have been using for more than a decade (e.g., text classification). But more importantly, they unlock entirely new types of tasks that bring about novel research opportunities (e.g., text summarization, and generative question answering). We conclude with a roadmap and research agenda for promising NLP applications in marketing and provide supplementary code examples to help interested scholars to explore opportunities related to NLP in marketing.},
  isbn = {978-1-80262-875-3 978-1-80262-876-0},
  keywords = {Computational linguistics,Deep learning,Language models,Natural language processing,Sentiment analysis,Text analytics,Text mining,Topic modeling,Transformers,Word embeddings},
  file = {/Users/hoener/Zotero/storage/MD2LYG2Z/html.html}
}

@misc{hartmannPowerGenerativeMarketing2024,
  type = {{{SSRN Scholarly Paper}}},
  title = {The Power of Generative Marketing: {{Can}} Generative {{AI}} Create Superhuman Visual Marketing Content?},
  shorttitle = {The Power of Generative Marketing},
  author = {Hartmann, Jochen and Exner, Yannick and Domdey, Samuel},
  year = {2024},
  month = apr,
  number = {4597899},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.4597899},
  urldate = {2024-06-04},
  abstract = {Generative AI's capacity to create photorealistic images has the potential to augment human creativity and disrupt the economics of visual marketing content production. This research systematically compares the performance of AI-generated to human-made marketing images across important marketing dimensions. First, we prompt seven state-of-the-art generative text-to-image models (DALL-E 3, Midjourney v6, Firefly 2, Imagen 2, Imagine, Realistic Vision, and Stable Diffusion XL Turbo) to create 10,320 synthetic marketing images, using 2,400 real-world, human-made images as input. 254,400 human evaluations of these images show that AI-generated marketing imagery can surpass human-made images in quality, realism, and aesthetics. Second, we give identical creative briefings to commissioned human freelancers and the AI models, showing that the best synthetic images also excel in ad creativity, ad attitudes, and prompt following. Third, a randomized field experiment with more than 173,000 impressions demonstrates that AI-generated online ads can compete with professional human-made stock photography, achieving an up to 50\% higher click-through rate than a human-made image. Collectively, our findings suggest that the paradigm shift brought about by generative AI can help advertisers produce marketing content not only faster and orders of magnitude cheaper but also at superhuman effectiveness levels with important implications for firms, consumers, and policymakers. To facilitate future research on AI-generated marketing imagery, we release ``GeneratedImageNet'' that contains all of our synthetic images and their human ratings.},
  langid = {english},
  keywords = {artificial intelligence,content creation,digital marketing,generative AI,marketing effectiveness,productivity}
}

@article{hermannArtificialIntelligenceConsumer2024,
  title = {Artificial Intelligence and Consumer Behavior: {{From}} Predictive to Generative {{AI}}},
  shorttitle = {Artificial Intelligence and Consumer Behavior},
  author = {Hermann, Erik and Puntoni, Stefano},
  year = {2024},
  month = jul,
  journal = {Journal of Business Research},
  volume = {180},
  pages = {114720},
  issn = {0148-2963},
  doi = {10.1016/j.jbusres.2024.114720},
  urldate = {2024-06-04},
  abstract = {Since the introduction of ChatGPT, the leading example of Generative Artificial Intelligence (GenAI), the research community and the general public have been captivated by GenAI's remarkable advances in performance, and its ability to both imitate and, in some respects, surpass human capabilities. This paper offers a comprehensive analysis of the impact of AI on consumer behavior, focusing on the two pivotal phases of AI development over the past 15~years. We start by reviewing the extensively researched, yet still growing, field of algorithmic predictions and decision-making, alongside the varied positive and negative consumer reactions it elicits. Subsequently, we delve into the just emerging field of GenAI. Here, we differentiate between Convergent Thinking GenAI, which is more domain-specific and geared towards pre-defined task completion, and Divergent Thinking GenAI, which is more domain-general and oriented towards new task fulfillment. For each of these realms, we identify key areas for future investigation.},
  keywords = {Algorithms,Artificial intelligence,Consumer behavior,Generative AI,Predictive AI}
}

@misc{holtzmanCuriousCaseNeural2020,
  title = {The {{Curious Case}} of {{Neural Text Degeneration}}},
  author = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  year = {2020},
  month = feb,
  number = {arXiv:1904.09751},
  eprint = {1904.09751},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1904.09751},
  urldate = {2024-06-14},
  abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/hoener/Zotero/storage/8IRJHFHI/Holtzman et al. - 2020 - The Curious Case of Neural Text Degeneration.pdf;/Users/hoener/Zotero/storage/B355CAA9/1904.html}
}

@article{hongWritingMoreCompelling2022,
  title = {Writing {{More Compelling Creative Appeals}}: {{A Deep Learning-Based Approach}}},
  shorttitle = {Writing {{More Compelling Creative Appeals}}},
  author = {Hong, Jiyeon and Hoban, Paul R.},
  year = {2022},
  month = sep,
  journal = {Marketing Science},
  volume = {41},
  number = {5},
  pages = {941--965},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2022.1351},
  urldate = {2024-06-07},
  abstract = {We present a deep learning algorithm to provide personalized feedback on creative appeals, written content intended to persuade readers to undertake some action. Such appeals are widespread in marketing, including advertising copy, RFP responses, call center scripts, product descriptions, and many others. Although marketing research has produced several tools to help managers glean insights from online word-of-mouth, less attention has been paid to creating tools to assist the innumerable marketers responsible for crafting effective marketing messages. Our approach leverages the hierarchical structure of written works, associating words with sentences and sentences with documents, and the linguistic relationships developed therein. We score each sentence in an appeal by its expected contribution to success accounting for its substance and persuasive impact. The sentences with the lowest scores make the appeal less compelling and are the most effective points to focus a revision. The approach has proved effective in a randomized control trial, with subjects rating essays revised with the aid of algorithmic feedback as being 4.5\% more likely to achieve their objectives. In addition to providing automated feedback to authors, we leverage the model's output to derive substantive insights into what makes an appeal compelling.},
  keywords = {creative appeals,deep learning,natural language processing,recurrent neural networks},
  file = {/Users/hoener/Zotero/storage/YVK5N2MJ/Hong and Hoban - 2022 - Writing More Compelling Creative Appeals A Deep L.pdf}
}

@article{huangenhanced,
  title = {Enhanced News Summarization Using Large Language Models and Advanced Prompt Engineering},
  author = {Huang, Zihao and Chen, Tao}
}

@misc{huggingfaceGenerateText,
  title = {How to Generate Text: Using Different Decoding Methods for Language Generation with {{Transformers}} --- Huggingface.Co}
}

@article{ianj.goodfellowGenerativeAdversarialNetworks2014,
  title = {Generative {{Adversarial Networks}}},
  author = {{Ian J. Goodfellow} and Goodfellow, Ian and Salvaris, Mathew and {Jean Pouget-Abadie} and Dean, Danielle and {Pouget-Abadie}, Jean and {Mehdi Mirza} and Tok, Wee Hyong and Mirza, Mehdi and {Bing Xu} and Xu, Bing and {David Warde-Farley} and {Warde-Farley}, David and {Sherjil Ozair} and Ozair, Sherjil and {Aaron Courville} and Courville, Aaron and {Yoshua Bengio} and Bengio, Yoshua},
  year = {2014},
  month = jun,
  journal = {arXiv: Machine Learning},
  doi = {10.1007/978-1-4842-3679-6_8},
  abstract = {For many AI projects, deep learning techniques are increasingly being used as the building blocks for innovative solutions ranging from image classification to object detection, image segmentation, image similarity, and text analytics (e.g., sentiment analysis, key phrase extraction). GANs, first introduced by Goodfellow et al. (2014), are emerging as a powerful new approach toward teaching computers how to do complex tasks through a generative process. As noted by Yann LeCun (at http://bit.ly/LeCunGANs ), GANs are truly the ``coolest idea in machine learning in the last 20 years.''},
  annotation = {MAG ID: 1710476689}
}

@misc{ioffeBatchNormalizationAccelerating2015,
  title = {Batch {{Normalization}}: {{Accelerating Deep Network Training}} by {{Reducing Internal Covariate Shift}}},
  shorttitle = {Batch {{Normalization}}},
  author = {Ioffe, Sergey and Szegedy, Christian},
  year = {2015},
  month = mar,
  number = {arXiv:1502.03167},
  eprint = {1502.03167},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1502.03167},
  urldate = {2024-06-17},
  abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/WGGNJ3BY/Ioffe and Szegedy - 2015 - Batch Normalization Accelerating Deep Network Tra.pdf;/Users/hoener/Zotero/storage/IGP85M9T/1502.html}
}

@article{iyerTargetingAdvertising2005,
  title = {The {{Targeting}} of {{Advertising}}},
  author = {Iyer, Ganesh and Soberman, David and {Villas-Boas}, J. Miguel},
  year = {2005},
  month = aug,
  journal = {Marketing Science},
  volume = {24},
  number = {3},
  pages = {461--476},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.1050.0117},
  urldate = {2024-06-06},
  abstract = {An important question that firms face in advertising is developing effective media strategy. Major improvements in the quality of consumer information and the growth of targeted media vehicles allow firms to precisely target advertising to consumer segments within a market. This paper examines advertising strategy when competing firms can target advertising to different groups of consumers within a market. With targeted advertising, we find that firms advertise more to consumers who have a strong preference for their product than to comparison shoppers who can be attracted to the competition. Advertising less to comparison shoppers can be seen as a way for firms to endogenously increase differentiation in the market. In addition, targeting allows the firm to eliminate ``wasted'' advertising to consumers whose preferences do not match a product's attributes. As a result, the targeting of advertising increases equilibrium profits. The model demonstrates how advertising strategies are affected by firms being able to target pricing. Target advertising leads to higher profits, regardless of whether or not the firms have the ability to set targeted prices, and the targeting of advertising can be more valuable for firms in a competitive environment than the ability to target pricing.},
  keywords = {advertising,media precision,price discrimination,targeting},
  file = {/Users/hoener/Zotero/storage/3J8E28MQ/Iyer et al. - 2005 - The Targeting of Advertising.pdf}
}

@article{jeffreypenningtonGloveGlobalVectors2014,
  title = {Glove: {{Global Vectors}} for {{Word Representation}}},
  author = {{Jeffrey Pennington} and Pennington, Jeffrey and {Richard Socher} and Socher, Richard and {Christopher Manning} and Manning, Christopher D.},
  year = {2014},
  month = oct,
  pages = {1532--1543},
  doi = {10.3115/v1/d14-1162},
  abstract = {Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75\% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.},
  annotation = {MAG ID: 2250539671}
}

@article{jurgensmeierGenerativeAIScalable2024,
  title = {Generative {{AI}} for Scalable Feedback to Multimodal Exercises},
  author = {J{\"u}rgensmeier, Lukas and Skiera, Bernd},
  year = {2024},
  month = may,
  journal = {International Journal of Research in Marketing},
  issn = {0167-8116},
  doi = {10.1016/j.ijresmar.2024.05.005},
  urldate = {2024-06-18},
  abstract = {Detailed feedback on exercises helps learners become proficient but is time-consuming for educators and, thus, hardly scalable. This manuscript evaluates how well Generative Artificial Intelligence (AI) provides automated feedback on complex multimodal exercises requiring coding, statistics, and economic reasoning. Besides providing this technology through an easily accessible web application, this article evaluates the technology's performance by comparing the quantitative feedback (i.e., points achieved) from Generative AI models with human expert feedback for 4,349 solutions to marketing analytics exercises. The results show that automated feedback produced by Generative AI (GPT-4) provides almost unbiased evaluations while correlating highly with (r~=~0.94) and deviating only 6~\% from human evaluations. GPT-4 performs best among seven Generative AI models, albeit at the highest cost. Comparing the models' performance with costs shows that GPT-4, Mistral Large, Claude 3 Opus, and Gemini 1.0 Pro dominate three other Generative AI models (Claude 3 Sonnet, GPT-3.5, and Gemini 1.5 Pro). Expert assessment of the qualitative feedback (i.e., the AI's textual response) indicates that it is mostly correct, sufficient, and appropriate for learners. A survey of marketing analytics learners shows that they highly recommend the app and its Generative AI feedback. An advantage of the app is its subject-agnosticism---it does not require any subject- or exercise-specific training. Thus, it is immediately usable for new exercises in marketing analytics and other subjects.},
  keywords = {Automated Feedback,Education,Generative AI,Learning,Marketing Analytics}
}

@misc{khattabDSPyCompilingDeclarative2023,
  title = {{{DSPy}}: {{Compiling Declarative Language Model Calls}} into {{Self-Improving Pipelines}}},
  shorttitle = {{{DSPy}}},
  author = {Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T. and Moazam, Hanna and Miller, Heather and Zaharia, Matei and Potts, Christopher},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03714},
  eprint = {2310.03714},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-12},
  abstract = {The ML community is rapidly exploring techniques for prompting language models (LMs) and for stacking them into pipelines that solve complex tasks. Unfortunately, existing LM pipelines are typically implemented using hard-coded ``prompt templates'', i.e. lengthy strings discovered via trial and error. Toward a more systematic approach for developing and optimizing LM pipelines, we introduce DSPy, a programming model that abstracts LM pipelines as text transformation graphs, i.e. imperative computation graphs where LMs are invoked through declarative modules. DSPy modules are parameterized, meaning they can learn (by creating and collecting demonstrations) how to apply compositions of prompting, finetuning, augmentation, and reasoning techniques. We design a compiler that will optimize any DSPy pipeline to maximize a given metric. We conduct two case studies, showing that succinct DSPy programs can express and optimize sophisticated LM pipelines that reason about math word problems, tackle multihop retrieval, answer complex questions, and control agent loops. Within minutes of compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to selfbootstrap pipelines that outperform standard few-shot prompting (generally by over 25\% and 65\%, respectively) and pipelines with expert-created demonstrations (by up to 5--46\% and 16--40\%, respectively). On top of that, DSPy programs compiled to open and relatively small LMs like 770M-parameter T5 and llama2-13b-chat are competitive with approaches that rely on expert-written prompt chains for proprietary GPT-3.5.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning,optimized prompting},
  file = {/Users/hoener/Zotero/storage/K3N5X38E/Khattab et al. - 2023 - DSPy Compiling Declarative Language Model Calls i.pdf}
}

@article{kongMadeUSAClaims2021,
  title = {Do ``{{Made}} in {{USA}}'' {{Claims Matter}}?},
  author = {Kong, Xinyao and Rao, Anita},
  year = {2021},
  month = jul,
  journal = {Marketing Science},
  volume = {40},
  number = {4},
  pages = {731--764},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2020.1274},
  urldate = {2024-06-06},
  abstract = {Firms often display product information on their front-of-package labels with some firms going as far as to make deceptive claims. We study the impact of the ``Made in USA'' claim---a disclosure not legally required on consumer-packaged goods and yet a claim highlighted by many firms, sometimes deceptively---on consumer demand. Leveraging the Federal Trade Commission's investigation of four brands that resulted in removal of the claim from product packages, we study the impact such removal had on sales. We find a decline in demand following the removal of the ``Made in USA'' claim. Second, to ensure complete exogenous variation, we conduct a field experiment on eBay, on which we run more than 900 auctions, varying only whether a product contains this country-of-origin information. We find that, although products with the ``Made in USA'' claim have a slightly higher chance of drawing a zero valuation, such products obtain a 44\% higher willingness-to-pay conditional on a positive valuation. However, this increased valuation is insufficient to economically justify firm relocation efforts. Auction transaction prices, on the other hand, are significantly and 28\% higher with the claim, suggesting resellers and auctioneers have incentives to display the claim. The experiments alongside observational data allow us to rationalize firms' incentives in making deceptive country-of-origin claims.},
  keywords = {country-of-origin,deceptive advertising,field experiments,FTC,natural experiments,public policy},
  file = {/Users/hoener/Zotero/storage/F6M6A6G3/Kong and Rao - 2021 - Do “Made in USA” Claims Matter.pdf}
}

@article{liFrontiersDeterminingValidity2024a,
  title = {Frontiers: {{Determining}} the {{Validity}} of {{Large Language Models}} for {{Automated Perceptual Analysis}}},
  shorttitle = {Frontiers},
  author = {Li, Peiyao and Castelo, Noah and Katona, Zsolt and Sarvary, Miklos},
  year = {2024},
  month = jan,
  journal = {Marketing Science},
  volume = {43},
  number = {2},
  pages = {254--266},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0454},
  urldate = {2024-05-13},
  abstract = {This paper explores the potential of large language models (LLMs) to substitute for human participants in market research. Such LLMs can be used to generate text given a prompt. We argue that perceptual analysis is a particularly promising use case for such automated market research for certain product categories. The proposed new method generates outputs that closely match those generated from human surveys: agreement rates between human- and LLM- generated data sets reach over 75\%. Moreover, this applies for perceptual analysis based on both brand similarity measures and product attribute ratings. The paper demonstrates that, for some categories, this new method of fully or partially automated market research will increase the efficiency of market research by meaningfully speeding up the process and potentially reducing the cost. Further results also suggest that with an ever larger training corpus applied to large language models, LLM-based market research will be applicable to answer more nuanced questions based on demographic variables or contextual variation that would be prohibitively expensive or infeasible with human respondents. History: Catherine Tucker served as the senior editor. This paper was accepted through the Marketing Science: Frontiers review process. Funding: This work was supported by the Social Sciences and Humanities Research Council of Canada [Grant 430-2021-00057]. Supplemental Material: The online appendix and data files are available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2023.0454.},
  keywords = {artificial Intelligence,large language model,market research,natural language processing,notion,perceptual maps},
  file = {/Users/hoener/Zotero/storage/HHANZHZZ/Li et al. - 2024 - Frontiers Determining the Validity of Large Langu.pdf}
}

@article{liFrontiersDeterminingValidity2024b,
  title = {Frontiers: {{Determining}} the {{Validity}} of {{Large Language Models}} for {{Automated Perceptual Analysis}}},
  shorttitle = {Frontiers},
  author = {Li, Peiyao and Castelo, Noah and Katona, Zsolt and Sarvary, Miklos},
  year = {2024},
  month = jan,
  journal = {Marketing Science},
  volume = {43},
  number = {2},
  pages = {254--266},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2023.0454},
  urldate = {2024-06-04},
  abstract = {This paper explores the potential of large language models (LLMs) to substitute for human participants in market research. Such LLMs can be used to generate text given a prompt. We argue that perceptual analysis is a particularly promising use case for such automated market research for certain product categories. The proposed new method generates outputs that closely match those generated from human surveys: agreement rates between human- and LLM- generated data sets reach over 75\%. Moreover, this applies for perceptual analysis based on both brand similarity measures and product attribute ratings. The paper demonstrates that, for some categories, this new method of fully or partially automated market research will increase the efficiency of market research by meaningfully speeding up the process and potentially reducing the cost. Further results also suggest that with an ever larger training corpus applied to large language models, LLM-based market research will be applicable to answer more nuanced questions based on demographic variables or contextual variation that would be prohibitively expensive or infeasible with human respondents.History: Catherine Tucker served as the senior editor. This paper was accepted through the Marketing Science: Frontiers review process.Funding: This work was supported by the Social Sciences and Humanities Research Council of Canada [Grant 430-2021-00057].Supplemental Material: The online appendix and data files are available at https://doi.org/10.1287/mksc.2023.0454.},
  keywords = {artificial Intelligence,large language model,market research,natural language processing,perceptual maps},
  file = {/Users/hoener/Zotero/storage/MEDC3Y49/Li et al. - 2024 - Frontiers Determining the Validity of Large Langu.pdf}
}

@misc{liGuidingLargeLanguage2023,
  title = {Guiding {{Large Language Models}} via {{Directional Stimulus Prompting}}},
  author = {Li, Zekun and Peng, Baolin and He, Pengcheng and Galley, Michel and Gao, Jianfeng and Yan, Xifeng},
  year = {2023},
  month = oct,
  number = {arXiv:2302.11520},
  eprint = {2302.11520},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.11520},
  urldate = {2024-06-13},
  abstract = {We introduce Directional Stimulus Prompting, a novel framework for guiding black-box large language models (LLMs) toward specific desired outputs. Instead of directly adjusting LLMs, our method employs a small tunable policy model (e.g., T5) to generate an auxiliary directional stimulus prompt for each input instance. These directional stimulus prompts act as nuanced, instance-specific hints and clues to guide LLMs in generating desired outcomes, such as including specific keywords in the generated summary. Our approach sidesteps the challenges of direct LLM tuning by optimizing the policy model to explore directional stimulus prompts that align LLMs with desired behaviors. The policy model can be optimized through 1) supervised fine-tuning using labeled data and 2) reinforcement learning from offline or online rewards based on the LLM's output. We assess our method across summarization, dialogue response generation, and chain-of-thought reasoning tasks. Our experiments demonstrate that the framework consistently improves LLMs' (e.g., ChatGPT, Codex, InstructGPT) performance on these supervised tasks using minimal labeled data. Notably, using just 80 dialogues on the MultiWOZ dataset, our approach enhances ChatGPT's performance by an impressive 41.4\%, matching or surpassing some fully supervised start-of-the-art models. Additionally, the instance-specific chain-of-thought prompt generated by our approach improves InstructGPT's reasoning accuracy compared to human-crafted or automatically generated prompts. The code and data are publicly available at {\textbackslash}url\{https://github.com/Leezekun/Directional-Stimulus-Prompting\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/hoener/Zotero/storage/Y9ZXCX8Z/Li et al. - 2023 - Guiding Large Language Models via Directional Stim.pdf;/Users/hoener/Zotero/storage/BH2VTZWX/2302.html}
}

@misc{liLargeLanguageModels2023,
  title = {Large {{Language Models Understand}} and {{Can}} Be {{Enhanced}} by {{Emotional Stimuli}}},
  author = {Li, Cheng and Wang, Jindong and Zhang, Yixuan and Zhu, Kaijie and Hou, Wenxin and Lian, Jianxun and Luo, Fang and Yang, Qiang and Xie, Xing},
  year = {2023},
  month = nov,
  number = {arXiv:2307.11760},
  eprint = {2307.11760},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-14},
  abstract = {Emotional intelligence significantly impacts our daily behaviors and interactions. Although Large Language Models (LLMs) are increasingly viewed as a stride toward artificial general intelligence, exhibiting impressive performance in numerous tasks, it is still uncertain if LLMs can genuinely grasp psychological emotional stimuli. Understanding and responding to emotional cues gives humans a distinct advantage in problem-solving. In this paper, we take the first step towards exploring the ability of LLMs to understand emotional stimuli. To this end, we first conduct automatic experiments on 45 tasks using various LLMs, including Flan-T5-Large, Vicuna, Llama 2, BLOOM, ChatGPT, and GPT-4. Our tasks span deterministic and generative applications that represent comprehensive evaluation scenarios. Our automatic experiments show that LLMs have a grasp of emotional intelligence, and their performance can be improved with emotional prompts (which we call ``EmotionPrompt'' that combines the original prompt with emotional stimuli), e.g., 8.00\% relative performance improvement in Instruction Induction and 115\% in BIG-Bench. In addition to those deterministic tasks that can be automatically evaluated using existing metrics, we conducted a human study with 106 participants to assess the quality of generative tasks using both vanilla and emotional prompts. Our human study results demonstrate that EmotionPrompt significantly boosts the performance of generative tasks (10.9\% average improvement in terms of performance, truthfulness, and responsibility metrics). We provide an in-depth discussion regarding why EmotionPrompt works for LLMs and the factors that may influence its performance. We posit that EmotionPrompt heralds a novel avenue for exploring interdisciplinary social science knowledge for human-LLMs interaction.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction},
  file = {/Users/hoener/Zotero/storage/99KMT4JH/Li et al. - 2023 - Large Language Models Understand and Can be Enhanc.pdf}
}

@misc{liuLostMiddleHow2023,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  shorttitle = {Lost in the {{Middle}}},
  author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  year = {2023},
  month = nov,
  number = {arXiv:2307.03172},
  eprint = {2307.03172},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.03172},
  urldate = {2024-06-13},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/hoener/Zotero/storage/MBUJMLFG/Liu et al. - 2023 - Lost in the Middle How Language Models Use Long C.pdf;/Users/hoener/Zotero/storage/K9ICS5X2/2307.html}
}

@misc{liuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  shorttitle = {{{RoBERTa}}},
  author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  number = {arXiv:1907.11692},
  eprint = {1907.11692},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-16},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/hoener/Zotero/storage/V9JKH8A3/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf}
}

@misc{luAreEmergentAbilities2023,
  title = {Are {{Emergent Abilities}} in {{Large Language Models}} Just {{In-Context Learning}}?},
  author = {Lu, Sheng and Bigoulaeva, Irina and Sachdeva, Rachneet and Madabushi, Harish Tayyar and Gurevych, Iryna},
  year = {2023},
  month = sep,
  number = {arXiv:2309.01809},
  eprint = {2309.01809},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.01809},
  urldate = {2024-06-14},
  abstract = {Large language models have exhibited emergent abilities, demonstrating exceptional performance across diverse tasks for which they were not explicitly trained, including those that require complex reasoning abilities. The emergence of such abilities carries profound implications for the future direction of research in NLP, especially as the deployment of such models becomes more prevalent. However, one key challenge is that the evaluation of these abilities is often confounded by competencies that arise in models through alternative prompting techniques, such as in-context learning and instruction following, which also emerge as the models are scaled up. In this study, we provide the first comprehensive examination of these emergent abilities while accounting for various potentially biasing factors that can influence the evaluation of models. We conduct rigorous tests on a set of 18 models, encompassing a parameter range from 60 million to 175 billion parameters, across a comprehensive set of 22 tasks. Through an extensive series of over 1,000 experiments, we provide compelling evidence that emergent abilities can primarily be ascribed to in-context learning. We find no evidence for the emergence of reasoning abilities, thus providing valuable insights into the underlying mechanisms driving the observed abilities and thus alleviating safety concerns regarding their use.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/hoener/Zotero/storage/ZNC48SIP/Lu et al. - 2023 - Are Emergent Abilities in Large Language Models ju.pdf;/Users/hoener/Zotero/storage/3E2RTXG8/2309.html}
}

@techreport{ludwigMachineLearningTool2023,
  title = {Machine {{Learning}} as a {{Tool}} for {{Hypothesis Generation}}},
  author = {Ludwig, Jens and Mullainathan, Sendhil},
  year = {2023},
  month = mar,
  number = {w31017},
  pages = {w31017},
  address = {Cambridge, MA},
  institution = {National Bureau of Economic Research},
  doi = {10.3386/w31017},
  urldate = {2023-10-12},
  langid = {english},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/YHISPA8M/Ludwig and Mullainathan - 2023 - Machine Learning as a Tool for Hypothesis Generati.pdf}
}

@article{maMachineLearningAI2020,
  title = {Machine Learning and {{AI}} in Marketing -- {{Connecting}} Computing Power to Human Insights},
  author = {Ma, Liye and Sun, Baohong},
  year = {2020},
  month = sep,
  journal = {International Journal of Research in Marketing},
  volume = {37},
  number = {3},
  pages = {481--504},
  issn = {0167-8116},
  doi = {10.1016/j.ijresmar.2020.04.005},
  urldate = {2024-06-04},
  abstract = {Artificial intelligence (AI) agents driven by machine learning algorithms are rapidly transforming the business world, generating heightened interest from researchers. In this paper, we review and call for marketing research to leverage machine learning methods. We provide an overview of common machine learning tasks and methods, and compare them with statistical and econometric methods that marketing researchers traditionally use. We argue that machine learning methods can process large-scale and unstructured data, and have flexible model structures that yield strong predictive performance. Meanwhile, such methods may lack model transparency and interpretability. We discuss salient AI-driven industry trends and practices, and review the still nascent academic marketing literature which uses machine learning methods. More importantly, we present a unified conceptual framework and a multi-faceted research agenda. From five key aspects of empirical marketing research: method, data, usage, issue, and theory, we propose a number of research priorities, including extending machine learning methods and using them as core components in marketing research, using the methods to extract insights from large-scale unstructured, tracking, and network data, using them in transparent fashions for descriptive, causal, and prescriptive analyses, using them to map out customer purchase journeys and develop decision-support capabilities, and connecting the methods to human insights and marketing theories. Opportunities abound for machine learning methods in marketing, and we hope our multi-faceted research agenda will inspire more work in this exciting area.},
  keywords = {Artificial intelligence (AI),Big data,Digital marketing,Interpretation,Machine learning,Marketing theory,Network,Prediction,Tracking data,Unstructured data},
  file = {/Users/hoener/Zotero/storage/QX824U72/S0167811620300410.html}
}

@article{mcgranaghanHowViewerTuning2022,
  title = {How {{Viewer Tuning}}, {{Presence}}, and {{Attention Respond}} to {{Ad Content}} and {{Predict Brand Search Lift}}},
  author = {McGranaghan, Matthew and Liaukonyte, Jura and Wilbur, Kenneth C.},
  year = {2022},
  month = sep,
  journal = {Marketing Science},
  volume = {41},
  number = {5},
  pages = {873--895},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2021.1344},
  urldate = {2024-06-06},
  abstract = {New technology measures TV viewer tuning, presence, and attention, enabling the first distinctions between TV ad viewability and actual ad viewing. We compare new and traditional viewing metrics to evaluate the new metrics' utility to advertisers. We find that 30\% of TV ads play to empty rooms. We then use broadcast networks' verifiably quasi-random ordering of ads within commercial breaks to estimate causal effects of ads on new viewing metrics among four million advertising exposures. We measure ad metadata and machine-code content features for 6,650 frequent ad videos. We find that recreational product ads preserve audience tuning and presence. Prescription drug advertisements decrease tuning and presence, more so for drugs that treat more prevalent and severe conditions. We also investigate whether new viewing data can inform advertiser objectives, finding that attention helps predict brand search lift after ads.},
  keywords = {ad avoidance,ad content,ad response,advertising,attention,audience measurement,Google Scholar},
  file = {/Users/hoener/Zotero/storage/Z7V95J34/McGranaghan et al. - 2022 - How Viewer Tuning, Presence, and Attention Respond.pdf}
}

@misc{MegaSynIntegratingGenerative,
  title = {{{MegaSyn}}: {{Integrating Generative Molecular Design}}, {{Automated Analog Designer}}, and {{Synthetic Viability Prediction}} {\textbar} {{ACS Omega}}},
  urldate = {2024-04-07},
  howpublished = {https://pubs.acs.org/doi/full/10.1021/acsomega.2c01404},
  keywords = {notion},
  file = {/Users/hoener/Zotero/storage/TNFMQTH7/acsomega.html}
}

@misc{metaMetaLlama,
  title = {Meta {{Llama}} 3 --- Llama.Meta.Com}
}

@article{mikolovDistributedRepresentationsWords2013,
  title = {Distributed {{Representations}} of {{Words}} and {{Phrases}} and Their {{Compositionality}}},
  author = {Mikolov, Tomas and {Ilya Sutskever} and Sutskever, Ilya and {Kai Chen} and Chen, Kai and {Kai Chen} and {Greg S. Corrado} and Corrado, Greg S. and {Jeff Dean} and Dean, Jeffrey},
  year = {2013},
  month = dec,
  volume = {26},
  pages = {3111--3119},
  abstract = {The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of "Canada" and "Air" cannot be easily combined to obtain "Air Canada". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.},
  annotation = {MAG ID: 2153579005}
}

@article{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and {Kai Chen} and Chen, Kai and {Kai Chen} and {Greg S. Corrado} and Corrado, Greg S. and {J. Michael Dean} and Dean, Jeffrey},
  year = {2013},
  month = jan,
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  annotation = {MAG ID: 1614298861}
}

@article{moorthyTargetingAdvertisingSpending2023,
  title = {Targeting {{Advertising Spending}} and {{Price}} on the {{Hotelling Line}}},
  author = {Moorthy, Sridhar and Shahrokhi Tehrani, Shervin},
  year = {2023},
  month = nov,
  journal = {Marketing Science},
  volume = {42},
  number = {6},
  pages = {1057--1079},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2022.1422},
  urldate = {2024-06-06},
  abstract = {Are competing firms better off with more targeting? We examine this question in the context of targeting advertising spending and price in the Hotelling model. By ``more targeting,'' we mean expanding the scope of targeting from one of these variables to both. When the incremental cost of such expansion is small, the question boils down to whether the firms are better off targeting both advertising spending and price (``full targeting'') or just one of them (``partial targeting''). We show that it is individually rational for the firms to expand the scope of targeting in such circumstances. However, their profits may or may not be higher in the resulting full targeting equilibrium. The paper identifies the conditions under which each type of targeting is collectively optimal. Targeting advertising spending only is optimal when the products are highly differentiated; however, when product differentiation is small, full targeting is optimal when the cost of advertising is small, and targeting price only is optimal when the cost of advertising is large. These results provide managerial guidance on how firms should respond to any restrictions on the scope of targeting imposed by regulators or online retail platforms. On the theoretical front, our results show that expanding the scope of targeting has benefits and costs for the firms. The benefits come from being able to align local advertising levels to local prices---what Dorfman and Steiner's theorem says firms should do. The costs come in the form of more intensified price competition, which takes different forms depending on which type of targeting is added. When price targeting is added to advertising spending targeting, it has the effect of replacing product differentiation by informational differentiation; when advertising spending targeting is added to price targeting, it has the effect of delegating control of the local price equilibrium to the weaker firm. Comparing our results with previous results suggests that targeting on preferences may be fundamentally different from targeting on loyalty and switching behaviors.History: Yuxin Chen served as the senior editor for this article.Funding: S. Moorthy was supported by the Social Sciences and Humanities Research Council of Canada [Grant 435-2017-0121].Supplemental Material: The online appendix is available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2022.1422.},
  keywords = {customized marketing,location-based targeting,targeted competition},
  file = {/Users/hoener/Zotero/storage/HKCDEJB3/Moorthy and Shahrokhi Tehrani - 2023 - Targeting Advertising Spending and Price on the Ho.pdf}
}

@article{netzerWhenWordsSweat2019,
  title = {When {{Words Sweat}}: {{Identifying Signals}} for {{Loan Default}} in the {{Text}} of {{Loan Applications}}},
  shorttitle = {When {{Words Sweat}}},
  author = {Netzer, Oded and Lemaire, Alain and Herzenstein, Michal},
  year = {2019},
  month = dec,
  journal = {Journal of Marketing Research},
  volume = {56},
  number = {6},
  pages = {960--980},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1177/0022243719852959},
  urldate = {2024-06-21},
  abstract = {The authors present empirical evidence that borrowers, consciously or not, leave traces of their intentions, circumstances, and personality traits in the text they write when applying for a loan. This textual information has a substantial and significant ability to predict whether borrowers will pay back the loan above and beyond the financial and demographic variables commonly used in models predicting default. The authors use text-mining and machine learning tools to automatically process and analyze the raw text in over 120,000 loan requests from Prosper, an online crowdfunding platform. Including in the predictive model the textual information in the loan significantly helps predict loan default and can have substantial financial implications. The authors find that loan requests written by defaulting borrowers are more likely to include words related to their family, mentions of God, the borrower's financial and general hardship, pleading lenders for help, and short-term-focused words. The authors further observe that defaulting loan requests are written in a manner consistent with the writing styles of extroverts and liars.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/KH9Y2ITX/Netzer et al. - 2019 - When Words Sweat Identifying Signals for Loan Def.pdf}
}

@inproceedings{NEURIPS2022_b1efde53,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
  editor = {Koyejo, S. and Mohamed, S. and Agarwal, A. and Belgrave, D. and Cho, K. and Oh, A.},
  year = {2022},
  volume = {35},
  pages = {27730--27744},
  publisher = {Curran Associates, Inc.}
}

@article{onanHierarchicalGraphbasedText2023,
  title = {Hierarchical Graph-Based Text Classification Framework with Contextual Node Embedding and {{BERT-based}} Dynamic Fusion},
  author = {Onan, Aytu{\u g}},
  year = {2023},
  month = jul,
  journal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {35},
  number = {7},
  pages = {101610},
  issn = {1319-1578},
  doi = {10.1016/j.jksuci.2023.101610},
  urldate = {2024-06-14},
  abstract = {We propose a novel hierarchical graph-based text classification framework that leverages the power of contextual node embedding and BERT-based dynamic fusion to capture the complex relationships between the nodes in the hierarchical graph and generate a more accurate classification of text. The framework consists of seven stages: Linguistic Feature Extraction, Hierarchical Node Construction with Domain-Specific Knowledge, Contextual Node Embedding, Multi-Level Graph Learning, Dynamic Text Sequential Feature Interaction, Attention-Based Graph Learning, and Dynamic Fusion with BERT. The first stage, Linguistic Feature Extraction, extracts the linguistic features of the text, including part-of-speech tags, dependency parsing, and named entities. The second stage constructs a hierarchical graph based on the domain-specific knowledge, which is used to capture the relationships between nodes in the graph. The third stage, Contextual Node Embedding, generates a vector representation for each node in the hierarchical graph, which captures its local context information, linguistic features, and domain-specific knowledge. The fourth stage, Multi-Level Graph Learning, uses a graph convolutional neural network to learn the hierarchical structure of the graph and extract the features of the nodes in the graph. The fifth stage, Dynamic Text Sequential Feature Interaction, captures the sequential information of the text and generates dynamic features for each node. The sixth stage, Attention-Based Graph earning, uses an attention mechanism to capture the important features of the nodes in the graph. Finally, the seventh stage, Dynamic Fusion with BERT, combines the output from the previous stages with the output from a pre-trained BERT model to obtain the final integrated vector representation of the text. This approach leverages the strengths of both the proposed framework and BERT, allowing for better performance on the classification task. The proposed framework was evaluated on several benchmark datasets and compared to state-of-the-art methods, demonstrating significant improvements in classification accuracy.},
  keywords = {Attention mechanism,Contextual embedding,Hierarchical graph,Pre-trained language models,Text classification},
  file = {/Users/hoener/Zotero/storage/CICNAPRU/S1319157823001647.html}
}

@article{ouyangTrainingLanguageModels2022,
  title = {Training Language Models to Follow Instructions with Human Feedback},
  author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F. and Leike, Jan and Lowe, Ryan},
  year = {2022},
  month = dec,
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {27730--27744},
  urldate = {2024-06-04},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/5SYHPV6I/Ouyang et al. - 2022 - Training language models to follow instructions wi.pdf}
}

@article{pearsonLIIILinesPlanes1901,
  title = {{{LIII}}. {{{\emph{On}}}}{\emph{ Lines and Planes of Closest Fit to Systems of Points in Space}}},
  author = {Pearson, Karl},
  year = {1901},
  month = nov,
  journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
  volume = {2},
  number = {11},
  pages = {559--572},
  issn = {1941-5982, 1941-5990},
  doi = {10.1080/14786440109462720},
  urldate = {2024-06-18},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/KQSIL37C/Pearson - 1901 - LIII. On lines and planes of closest fit to sys.pdf}
}

@book{phoenix2024prompt,
  title = {Prompt Engineering for Generative {{AI}}},
  author = {Phoenix, J. and Taylor, M.},
  year = {2024},
  publisher = {O'Reilly Media},
  isbn = {978-1-09-815340-3}
}

@misc{ProductAestheticDesign,
  title = {Product {{Aesthetic Design}}: {{A Machine Learning Augmentation}}},
  shorttitle = {Product {{Aesthetic Design}}},
  doi = {10.1287/mksc.2022.1429},
  urldate = {2024-06-06},
  howpublished = {https://pubsonline-informs-org.vu-nl.idm.oclc.org/doi/epdf/10.1287/mksc.2022.1429},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/NRTFV5JG/Product Aesthetic Design A Machine Learning Augme.pdf;/Users/hoener/Zotero/storage/K39RJFKN/mksc.2022.html}
}

@article{puntoniConsumersArtificialIntelligence2021b,
  title = {Consumers and {{Artificial Intelligence}}: {{An Experiential Perspective}}},
  shorttitle = {Consumers and {{Artificial Intelligence}}},
  author = {Puntoni, Stefano and Reczek, Rebecca Walker and Giesler, Markus and Botti, Simona},
  year = {2021},
  month = jan,
  journal = {Journal of Marketing},
  volume = {85},
  number = {1},
  pages = {131--151},
  publisher = {SAGE Publications Inc},
  issn = {0022-2429},
  doi = {10.1177/0022242920953847},
  urldate = {2024-06-04},
  abstract = {Artificial intelligence (AI) helps companies offer important benefits to consumers, such as health monitoring with wearable devices, advice with recommender systems, peace of mind with smart household products, and convenience with voice-activated virtual assistants. However, although AI can be seen as a neutral tool to be evaluated on efficiency and accuracy, this approach does not consider the social and individual challenges that can occur when AI is deployed. This research aims to bridge these two perspectives: on one side, the authors acknowledge the value that embedding AI technology into products and services can provide to consumers. On the other side, the authors build on and integrate sociological and psychological scholarship to examine some of the costs consumers experience in their interactions with AI. In doing so, the authors identify four types of consumer experiences with AI: (1) data capture, (2) classification, (3) delegation, and (4) social. This approach allows the authors to discuss policy and managerial avenues to address the ways in which consumers may fail to experience value in organizations' investments into AI and to lay out an agenda for future research.},
  langid = {english}
}

@article{radford2018improving,
  title = {Improving Language Understanding by Generative Pre-Training},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year = {2018},
  publisher = {OpenAI},
  keywords = {notion}
}

@article{radfordLanguageModelsAre,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/VS67H2I5/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf}
}

@misc{ramachandranSearchingActivationFunctions2017,
  title = {Searching for {{Activation Functions}}},
  author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
  year = {2017},
  month = oct,
  number = {arXiv:1710.05941},
  eprint = {1710.05941},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-17},
  abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, f (x) = x {$\cdot$} sigmoid({$\beta$}x), which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9\% for Mobile NASNet-A and 0.6\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/hoener/Zotero/storage/8P6JUY5D/Ramachandran et al. - 2017 - Searching for Activation Functions.pdf}
}

@misc{ramachandranSearchingActivationFunctions2017a,
  title = {Searching for {{Activation Functions}}},
  author = {Ramachandran, Prajit and Zoph, Barret and Le, Quoc V.},
  year = {2017},
  month = oct,
  number = {arXiv:1710.05941},
  eprint = {1710.05941},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-06-17},
  abstract = {The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, \$f(x) = x {\textbackslash}cdot {\textbackslash}text\{sigmoid\}({\textbackslash}beta x)\$, which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9{\textbackslash}\% for Mobile NASNet-A and 0.6{\textbackslash}\% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/Users/hoener/Zotero/storage/LPQ3Z424/Ramachandran et al. - 2017 - Searching for Activation Functions.pdf;/Users/hoener/Zotero/storage/8RDL6E46/1710.html}
}

@article{reimersSentenceBERTSentenceEmbeddings2019,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1908.10084},
  urldate = {2023-07-09},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  copyright = {Creative Commons Attribution Share Alike 4.0 International},
  keywords = {Computation and Language (cs.CL),embedding,FOS: Computer and information sciences,llm,notion}
}

@article{renAdvertisingContentCreation2023,
  title = {Advertising and {{Content Creation}} on {{Digital Content Platforms}}},
  author = {Ren, Qitian},
  year = {2023},
  month = dec,
  journal = {Marketing Science},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2022.0387},
  urldate = {2024-06-06},
  abstract = {This paper investigates the interplay between advertising and decentralized content creation on digital content platforms, such as YouTube, TikTok, and Instagram. Unlike traditional media, content on these platforms is produced by numerous creators competing for viewer attention. This study addresses how a platform's advertising policy (specifically, the level of advertising embedded in organic content) and various market factors, including viewers' satiation rates and their distaste for ads, influence decentralized content creation, exploring the ensuing implications for the platform's advertising and revenue-sharing policy design. Using a game-theoretical model, the research reveals that the level of advertising, viewers' satiation rates, and their distaste for ads can have a nonmonotonic impact on the equilibrium content quality. Contrary to conventional wisdom, a low level of advertising could be advantageous for platforms when viewers are inclined to consume high volumes of content, factoring in the strategic influence on content creation. Additionally, revenue sharing with creators depends on factors such as the viewers' satiation rates and the creators' creative costs. This study offers content platforms strategic guidance on refining their advertising and revenue-sharing policies in the creator economy.History: Anthony Dukes served as the senior editor.Funding: This work was supported by the National Natural Science Foundation of China [Grant 72332004].Supplemental Material: The online appendix is available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2022.0387.},
  keywords = {advertising,content creation,creator economy,digital platforms,game theory,revenue sharing},
  file = {/Users/hoener/Zotero/storage/XRAQZ2UH/Ren - 2023 - Advertising and Content Creation on Digital Conten.pdf}
}

@article{sahlgren2008distributional,
  title = {The Distributional Hypothesis},
  author = {Sahlgren, Magnus},
  year = {2008},
  journal = {Italian Journal of linguistics},
  volume = {20},
  pages = {33--53}
}

@article{sahniPersonalizationEmailMarketing2018,
  title = {Personalization in {{Email Marketing}}: {{The Role}} of {{Noninformative Advertising Content}}},
  shorttitle = {Personalization in {{Email Marketing}}},
  author = {Sahni, Navdeep S. and Wheeler, S. Christian and Chintagunta, Pradeep},
  year = {2018},
  month = mar,
  journal = {Marketing Science},
  volume = {37},
  number = {2},
  pages = {236--258},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2017.1066},
  urldate = {2024-06-06},
  abstract = {In collaboration with three companies selling a diverse set of products, we conducted randomized field experiments in which experimentally tailored email ads were sent to millions of individuals. We found consistently that personalizing the emails by adding consumer-specific information (e.g., recipient's name) benefited the advertisers. Importantly, such content is not likely to be informative about the advertised product or the company. In our main experiment, we found that adding the name of the message recipient to the email's subject line increased the probability of the recipient opening it by 20\% (from 9.05\% to 10.80\%), which translated to an increase in sales' leads by 31\% (from 0.39\% to 0.51\%) and a reduction in the number of individuals unsubscribing from the email campaign by 17\% (from 1.2\% to 1.0\%). We present similar experiments conducted with other companies, which show that the effects we document extend from objectives ranging from acquiring new customers to retaining customers who have purchased from the company in the past. Our investigation of several possible mechanisms suggests that such content increases the effort consumers make in processing the other content in the rest of the advertising message. Our paper quantifies the benefits from personalization and sheds light on the role of noninformative advertising content by analyzing several detailed measures of recipient's interaction with the message. It provides external validity to psychological mechanisms and has clear implications for the firms that are designing their advertising campaigns.Data and the online appendix are available at https://doi.org/10.1287/mksc.2017.1066.},
  keywords = {advertising,advertising content,advertising tailoring,email marketing,experimental design,field experiments,personalization},
  file = {/Users/hoener/Zotero/storage/X9D7ZBCT/Sahni et al. - 2018 - Personalization in Email Marketing The Role of No.pdf}
}

@article{shenBaselineNeedsMore2018,
  title = {Baseline {{Needs More Love}}: {{On Simple Word-Embedding-Based Models}} and {{Associated Pooling Mechanisms}}},
  shorttitle = {Baseline {{Needs More Love}}},
  author = {Shen, Dinghan and Wang, Guoyin and Wang, Wenlin and Min, Martin Renqiang and Su, Qinliang and Zhang, Yizhe and Li, Chunyuan and Henao, Ricardo and Carin, Lawrence},
  year = {2018},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.1805.09843},
  urldate = {2023-07-09},
  abstract = {Many deep learning architectures have been proposed to model the compositionality in text sequences, requiring a substantial number of parameters and expensive computations. However, there has not been a rigorous evaluation regarding the added value of sophisticated compositional functions. In this paper, we conduct a point-by-point comparative study between Simple Word-Embedding-based Models (SWEMs), consisting of parameter-free pooling operations, relative to word-embedding-based RNN/CNN models. Surprisingly, SWEMs exhibit comparable or even superior performance in the majority of cases considered. Based upon this understanding, we propose two additional pooling strategies over learned word embeddings: (i) a max-pooling operation for improved interpretability; and (ii) a hierarchical pooling operation, which preserves spatial (n-gram) information within text sequences. We present experiments on 17 datasets encompassing three tasks: (i) (long) document classification; (ii) text sequence matching; and (iii) short text tasks, including classification and tagging. The source code and datasets can be obtained from https:// github.com/dinghanshen/SWEM.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Artificial Intelligence (cs.AI),Computation and Language (cs.CL),FOS: Computer and information sciences,Machine Learning (cs.LG),notion},
  file = {/Users/hoener/Downloads/1805.09843v1.pdf}
}

@article{shulmanEditorialMarketingRole2023,
  title = {Editorial: {{Marketing}}'s {{Role}} in the {{Evolving Discipline}} of {{Product Management}}},
  shorttitle = {Editorial},
  author = {Shulman, Jeffrey D. and Toubia, Olivier and Saddler, Raena},
  year = {2023},
  month = jan,
  journal = {Marketing Science},
  volume = {42},
  number = {1},
  pages = {1--5},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2022.1428},
  urldate = {2024-06-07},
  abstract = {Product managers have tremendous power to change lives by setting the priorities for innovation. As the product management discipline continues to evolve and grow in popularity, there is an opportunity to strengthen mutually beneficial connections between the practice of product management and academic marketing research. For product managers, marketing academia can be an untapped knowledge resource. For marketing academics, there is an opportunity to directly influence product managers through creating rigorous and relevant research that will shape the courses taught on this increasingly popular topic. This editorial highlights the opportunity to shape the product management discipline, demonstrates that the marketing literature has a body of knowledge on which further contributions to product management can be based, and shares knowledge gaps that the Marketing Science community is capable of addressing.},
  file = {/Users/hoener/Zotero/storage/V7G6DUJM/Shulman et al. - 2023 - Editorial Marketing’s Role in the Evolving Discip.pdf}
}

@article{shulmanEditorialMarketingRole2023a,
  title = {Editorial: {{Marketing}}'s {{Role}} in the {{Evolving Discipline}} of {{Product Management}}},
  shorttitle = {Editorial},
  author = {Shulman, Jeffrey D. and Toubia, Olivier and Saddler, Raena},
  year = {2023},
  month = jan,
  journal = {Marketing Science},
  volume = {42},
  number = {1},
  pages = {1--5},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2022.1428},
  urldate = {2024-06-07},
  abstract = {Product managers have tremendous power to change lives by setting the priorities for innovation. As the product management discipline continues to evolve and grow in popularity, there is an opportunity to strengthen mutually beneficial connections between the practice of product management and academic marketing research. For product managers, marketing academia can be an untapped knowledge resource. For marketing academics, there is an opportunity to directly influence product managers through creating rigorous and relevant research that will shape the courses taught on this increasingly popular topic. This editorial highlights the opportunity to shape the product management discipline, demonstrates that the marketing literature has a body of knowledge on which further contributions to product management can be based, and shares knowledge gaps that the Marketing Science community is capable of addressing.},
  file = {/Users/hoener/Zotero/storage/ILWH9FPX/Shulman et al. - 2023 - Editorial Marketing’s Role in the Evolving Discip.pdf}
}

@article{sobermanDesigningContentAdvertising2022,
  title = {Designing the Content of Advertising in a Differentiated Market},
  author = {Soberman, David A. and Xiang, Yi},
  year = {2022},
  month = mar,
  journal = {International Journal of Research in Marketing},
  volume = {39},
  number = {1},
  pages = {190--211},
  issn = {0167-8116},
  doi = {10.1016/j.ijresmar.2021.06.005},
  urldate = {2024-06-07},
  abstract = {In many markets, consumers use attribute information to assess the value they expect from purchasing a product or service. This includes many low involvement experience goods including take-out food, many packaged good categories and restaurants. In these markets, quality differences exist but many differences are horizontal in nature: the consumer is interested in finding a product that meets her unique tastes. Beyond ensuring that consumers know the brand, the category and the price; it seems advertising should provide consumers with attribute information. However, a significant proportion of advertising does not provide it. In fact, within the same category, competitors respond to messages that emphasize detailed attribute information with messages that are devoid of attribute information. These messages are uninformative about product attributes. We explore how competition in a differentiated market is affected by the ability of a firm has to choose uninformative messages. We construct a model to investigate the factors that affect a firm's decision to use advertising with detailed attribute information or advertising that does not provide it. The model demonstrates that content decisions about advertising are affected by the differences between products, the range of heterogeneity in consumer tastes and the degree to which costs increase as a function of the quantity of information in advertising. Surprisingly, even when the cost to increase the quantity of information in advertising is low, uninformative campaigns can be more profitable than campaigns with attribute information. The analysis also demonstrates that firms can be more likely to provide attribute information when there are less consumers that are attribute-sensitive. Finally, the model shows that uninformative messages can create ``artificial differentiation'' in some situations.},
  keywords = {Advertising content,Horizontal differentiation,Matching,Uninformative messages},
  file = {/Users/hoener/Zotero/storage/D4SVK87G/S0167811621000483.html}
}

@article{sprenger2021simpson,
  title = {Simpson's Paradox},
  author = {Sprenger, Jan and Weinberger, Naftali},
  year = {2021}
}

@article{tatsunorihashimotoUnifyingHumanStatistical2019,
  title = {Unifying {{Human}} and {{Statistical Evaluation}} for {{Natural Language Generation}}},
  author = {{Tatsunori Hashimoto} and Hashimoto, Tatsunori B. and {Hugh Zhang} and Zhang, Hugh and {Percy Liang} and Liang, Percy},
  year = {2019},
  month = apr,
  journal = {arXiv: Computation and Language},
  abstract = {How can we measure whether a natural language generation system produces both high quality and diverse outputs? Human evaluation captures quality but not diversity, as it does not catch models that simply plagiarize from the training set. On the other hand, statistical evaluation (i.e., perplexity) captures diversity but not quality, as models that occasionally emit low quality samples would be insufficiently penalized. In this paper, we propose a unified framework which evaluates both diversity and quality, based on the optimal error rate of predicting whether a sentence is human- or machine-generated. We demonstrate that this error rate can be efficiently estimated by combining human and statistical evaluation, using an evaluation metric which we call HUSE. On summarization and chit-chat dialogue, we show that (i) HUSE detects diversity defects which fool pure human evaluation and that (ii) techniques such as annealing for improving quality actually decrease HUSE due to decreased diversity.},
  keywords = {evaluation,generation,Generative AI,llm},
  annotation = {MAG ID: 2941169998}
}

@article{timoshenkoIdentifyingCustomerNeeds2019,
  title = {Identifying {{Customer Needs}} from {{User-Generated Content}}},
  author = {Timoshenko, Artem and Hauser, John R.},
  year = {2019},
  month = jan,
  journal = {Marketing Science},
  volume = {38},
  number = {1},
  pages = {1--20},
  publisher = {INFORMS},
  issn = {0732-2399},
  doi = {10.1287/mksc.2018.1123},
  urldate = {2024-06-07},
  abstract = {Firms traditionally rely on interviews and focus groups to identify customer needs for marketing strategy and product development. User-generated content (UGC) is a promising alternative source for identifying customer needs. However, established methods are neither efficient nor effective for large UGC corpora because much content is noninformative or repetitive. We propose a machine-learning approach to facilitate qualitative analysis by selecting content for efficient review. We use a convolutional neural network to filter out noninformative content and cluster dense sentence embeddings to avoid sampling repetitive content. We further address two key questions: Are UGC-based customer needs comparable to interview-based customer needs? Do the machine-learning methods improve customer-need identification? These comparisons are enabled by a custom data set of customer needs for oral care products identified by professional analysts using industry-standard experiential interviews. The analysts also coded 12,000 UGC sentences to identify which previously identified customer needs and/or new customer needs were articulated in each sentence. We show that (1) UGC is at least as valuable as a source of customer needs for product development, likely more valuable, compared with conventional methods, and (2) machine-learning methods improve efficiency of identifying customer needs from UGC (unique customer needs per unit of professional services cost).Data are available at https://doi-org.vu-nl.idm.oclc.org/10.1287/mksc.2018.1123.},
  keywords = {customer needs,deep learning,machine learning,market research,natural language processing,online reviews,text mining,user-generated content,voice of the customer},
  file = {/Users/hoener/Zotero/storage/KTDC6T5X/Timoshenko and Hauser - 2019 - Identifying Customer Needs from User-Generated Con.pdf}
}

@article{toubiaPoissonFactorizationTopic2021,
  title = {A {{Poisson Factorization Topic Model}} for the {{Study}} of {{Creative Documents}} (and {{Their Summaries}})},
  author = {Toubia, Olivier},
  year = {2021},
  month = dec,
  journal = {Journal of Marketing Research},
  volume = {58},
  number = {6},
  pages = {1142--1158},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1177/0022243720943209},
  urldate = {2024-06-07},
  abstract = {The author proposes a topic model tailored to the study of creative documents (e.g., academic papers, movie scripts), which extends Poisson factorization in two ways. First, the creativity literature emphasizes the importance of novelty in creative industries. Accordingly, this article introduces a set of residual topics that represent the portion of each document that is not explained by a combination of common topics. Second, creative documents are typically accompanied by summaries (e.g., abstracts, synopses). Accordingly, the author jointly models the content of creative documents and their summaries, and captures systematic variations in topic intensities between the documents and their summaries. This article validates and illustrates the model in three domains: marketing academic papers, movie scripts, and TV show closed captions. It illustrates how the joint modeling of documents and summaries provides some insight into how people summarize creative documents and enhances understanding of the significance of each topic. It shows that the model described produces new measures of distinctiveness that can inform the perennial debate on the relation between novelty and success in creative industries. Finally, the author shows how the proposed model may form the basis for decision support tools that assist people in writing summaries of creative documents.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/CG5VQ66Y/Toubia - 2021 - A Poisson Factorization Topic Model for the Study .pdf}
}

@article{tuckerSocialNetworksPersonalized2014,
  title = {Social {{Networks}}, {{Personalized Advertising}}, and {{Privacy Controls}}},
  author = {Tucker, Catherine E.},
  year = {2014},
  month = oct,
  journal = {Journal of Marketing Research},
  volume = {51},
  number = {5},
  pages = {546--562},
  publisher = {SAGE Publications Inc},
  issn = {0022-2437},
  doi = {10.1509/jmr.10.0355},
  urldate = {2024-06-04},
  abstract = {This article investigates how Internet users' perceptions of control over their personal information affect how likely they are to click on online advertising on a social networking website. The analysis uses data from a randomized field experiment that examined the effectiveness of personalizing ad text with user-posted personal information relative to generic text. The website gave users more control over their personally identifiable information in the middle of the field test. However, the website did not change how advertisers used data to target and personalize ads. Before the policy change, personalized ads did not perform particularly well. However, after this enhancement of perceived control over privacy, users were nearly twice as likely to click on personalized ads. Ads that targeted but did not use personalized text remained unchanged in effectiveness. The increase in effectiveness was larger for ads that used more unique private information to personalize their message and for target groups that were more likely to use opt-out privacy settings.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/J8YUTM46/Tucker - 2014 - Social Networks, Personalized Advertising, and Pri.pdf}
}

@article{vaswani2017attention,
  title = {Attention Is All You Need},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  year = {2017},
  journal = {Advances in neural information processing systems},
  volume = {30},
  keywords = {notion}
}

@misc{wangDisentangledRepresentationLearning2024,
  title = {Disentangled {{Representation Learning}}},
  author = {Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  year = {2024},
  month = may,
  number = {arXiv:2211.11695},
  eprint = {2211.11695},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.11695},
  urldate = {2024-05-29},
  abstract = {Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, and data mining. In this article, we comprehensively investigate DRL from various aspects including motivations, definitions, methodologies, evaluations, applications, and model designs. We first present two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition for disentangled representation learning. We further categorize the methodologies for DRL into four groups from the following perspectives, the model type, representation structure, supervision signal, and independence assumption. We also analyze principles to design different DRL models that may benefit different tasks in practical applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this work may provide insights for promoting the DRL research in the community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/BJKSADUV/Wang et al. - 2024 - Disentangled Representation Learning.pdf;/Users/hoener/Zotero/storage/J2NTYGXR/2211.html}
}

@misc{wangDisentangledRepresentationLearning2024a,
  title = {Disentangled {{Representation Learning}}},
  author = {Wang, Xin and Chen, Hong and Tang, Si'ao and Wu, Zihao and Zhu, Wenwu},
  year = {2024},
  month = may,
  number = {arXiv:2211.11695},
  eprint = {2211.11695},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-29},
  abstract = {Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controlability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, and data mining. In this article, we comprehensively investigate DRL from various aspects including motivations, definitions, methodologies, evaluations, applications, and model designs. We first present two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition for disentangled representation learning. We further categorize the methodologies for DRL into four groups from the following perspectives, the model type, representation structure, supervision signal, and independence assumption. We also analyze principles to design different DRL models that may benefit different tasks in practical applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this work may provide insights for promoting the DRL research in the community.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/hoener/Zotero/storage/AI7GI9G5/Wang et al. - 2024 - Disentangled Representation Learning.pdf}
}

@article{weiEmergentAbilitiesLarge,
  title = {Emergent {{Abilities}} of {{Large Language Models}}},
  author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
  abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence raises the question of whether additional scaling could potentially further expand the range of capabilities of language models.},
  langid = {english},
  file = {/Users/hoener/Zotero/storage/MCT259A8/Wei et al. - Emergent Abilities of Large Language Models.pdf}
}

@article{yinhanliuRoBERTaRobustlyOptimized2019,
  title = {{{RoBERTa}}: {{A Robustly Optimized BERT Pretraining Approach}}},
  author = {{Yinhan Liu} and Liu, Yinhan and {Myle Ott} and Ott, Myle and {Naman Goyal} and Goyal, Naman and {Jingfei Du} and Du, Jingfei and {Mandar Joshi} and Joshi, Mandar and {Danqi Chen} and Chen, Danqi and {Omer Levy} and Levy, Omer and {Mike Lewis} and Lewis, Michael and {Michael Lewis} and {Michael Lewis} and Lewis, Mike and {Luke Zettlemoyer} and Zettlemoyer, Luke and {Veselin Stoyanov} and Stoyanov, Veselin},
  year = {2019},
  month = jul,
  journal = {arXiv: Computation and Language},
  abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of BERT pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that BERT was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on GLUE, RACE and SQuAD. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
  annotation = {MAG ID: 2965373594}
}

@inproceedings{zamfirescu2023johnny,
  title = {Why {{Johnny}} Can't Prompt: How Non-{{AI}} Experts Try (and Fail) to Design {{LLM}} Prompts},
  booktitle = {Proceedings of the 2023 {{CHI}} Conference on Human Factors in Computing Systems},
  author = {{Zamfirescu-Pereira}, {\relax JD} and Wong, Richmond Y and Hartmann, Bjoern and Yang, Qian},
  year = {2023},
  pages = {1--21}
}

@misc{zhangWhyGradientClipping2020,
  title = {Why Gradient Clipping Accelerates Training: {{A}} Theoretical Justification for Adaptivity},
  shorttitle = {Why Gradient Clipping Accelerates Training},
  author = {Zhang, Jingzhao and He, Tianxing and Sra, Suvrit and Jadbabaie, Ali},
  year = {2020},
  month = feb,
  number = {arXiv:1905.11881},
  eprint = {1905.11881},
  primaryclass = {cs, math},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1905.11881},
  urldate = {2024-06-20},
  abstract = {We provide a theoretical explanation for the effectiveness of gradient clipping in training deep neural networks. The key ingredient is a new smoothness condition derived from practical neural network training examples. We observe that gradient smoothness, a concept central to the analysis of first-order optimization algorithms that is often assumed to be a constant, demonstrates significant variability along the training trajectory of deep neural networks. Further, this smoothness positively correlates with the gradient norm, and contrary to standard assumptions in the literature, it can grow with the norm of the gradient. These empirical observations limit the applicability of existing theoretical analyses of algorithms that rely on a fixed bound on smoothness. These observations motivate us to introduce a novel relaxation of gradient smoothness that is weaker than the commonly used Lipschitz smoothness assumption. Under the new condition, we prove that two popular methods, namely, {\textbackslash}emph\{gradient clipping\} and {\textbackslash}emph\{normalized gradient\}, converge arbitrarily faster than gradient descent with fixed stepsize. We further explain why such adaptively scaled gradient methods can accelerate empirical convergence and verify our results empirically in popular neural network training settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  file = {/Users/hoener/Zotero/storage/NXX44DFC/Zhang et al. - 2020 - Why gradient clipping accelerates training A theo.pdf;/Users/hoener/Zotero/storage/4UHC5N2Q/1905.html}
}
